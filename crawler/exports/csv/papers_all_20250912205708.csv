id,title,abstract,doi,url,journal,pub_date,authors,type,created_at,updated_at
116,Test Nature Paper - Modified Parser,This is a test abstract for the modified Nature parser.,test-nature-20250912164551,https://www.nature.com/test/article,Nature,2025-09-12,Test Author,test,2025-09-12T16:45:51,2025-09-12T16:45:51
189,Causal inference unveils how forest coverage mitigates excess snakebite cases during rainfall seasons in Colombia,"Snakebite envenoming is a neglected tropical disease that affects mainly rural populations, where antivenom is scarce. Understanding environmental drivers of snakebite incidence is critical for public health preparedness. This study employs causal inference to assess the impact of rainfall on snakebite surges in Colombia, with broader implications for tropical regions. Using a spatiotemporal database of monthly snakebite case data (2007–2021), we applied machine learning models to estimate the causal effect of rainfall, considering nine atmospheric and oceanic indices, forest coverage, and rural GDP. High rainfall significantly causes excess snakebite cases (i.e., increasing the likelihood that the number of cases exceeds what is expected based on the standardized incidence ratio): a one-standard-deviation increase in rainfall (134.65 mm) led to a 2.1% rise in excess snakebite cases (95% CI 1.3–2.9). Forest coverage exhibited an inverse relationship with the impact of rainfall on excess cases, which is positive in regions with < 50% forest cover. These findings highlight the need for climate-adaptive public health strategies. Deforested regions face heightened snakebite risk during heavy rainfall, emphasizing the role of deforestation in shaping disease dynamics. As climate change alters precipitation patterns, integrating ecological and epidemiological data is crucial for forecasting and mitigating snakebite burden globally.",s41598-025-17405-3,https://www.nature.com/articles/s41598-025-17405-3,Scientific Reports,2025-09-10,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
162,Deciphering regulatory sequence grammar,"Leveraging data generated by UUATAC-seq, a method for cross-species chromatin accessibility profiling, the deep learning model NvwaCE decipherscis-regulatory grammar from DNA sequence. Authors and AffiliationsNature Methodshttps://www.nature.com/nmeth/Lei TangAuthorsLei TangView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorCorrespondence toLei Tang. Reprints and permissions Cite this articleTang, L. Deciphering regulatory sequence grammar.Nat Methods(2025). https://doi.org/10.1038/s41592-025-02827-8Download citationPublished:10 September 2025DOI:https://doi.org/10.1038/s41592-025-02827-8Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41592-025-02827-8,https://www.nature.com/articles/s41592-025-02827-8,Nature Methods,2025-09-10,,incremental,2025-09-12T17:57:09,2025-09-12T17:57:09
161,Benchmarking genomic language models,"Supervised deep learning models have a dazzling track record in many computational genomics tasks, but their success relies on vast (and often costly) experimental data for training. Recently, genomic language models (gLMs), whose pretraining needs only (although large numbers of) DNA sequences, have manifested as a potentially appealing alternative and are interesting many researchers in the genomics and computational biology community, including Peter Koo of Cold Spring Harbor Laboratory. “We were initially excited by the growing class of gLMs that aim to learn unsupervised representations of DNA,” he says. However, after building these models with his team, “We found that they consistently underperformed well-established supervised models.” Intrigued to know whether these observations prevail more generally, Koo and his colleagues shifted their project to perform a rigorous evaluation of gLMs.Challenges abound for benchmarking analysis in such a fast-paced area. Although new gLMs keep emerging, issues with code and data availability often hinder full reproducibility. “Many functional genomics modeling papers provided code and data, but these were often incomplete or difficult to adapt,” says Koo. This led the team to concentrate on a small but representative set of gLMs whose data and model baselines could be reliably obtained. Another important distinction of their benchmarking study compared to previous efforts is the tasks they designed. “The key innovation of our evaluation is its focus on biologically aligned tasks that are tied to open questions in gene regulation,” notes Koo. “In contrast, most existing benchmarks rely on classification tasks that originated in the machine learning literature and continue to be propagated in gLM studies, despite being disconnected from how models would be used to advance biological understanding and discovery.”",s41592-025-02829-6,https://www.nature.com/articles/s41592-025-02829-6,Nature Methods,2025-09-10,,incremental,2025-09-12T17:57:09,2025-09-12T17:57:09
156,AI models help diagnose inflammatory arthritis,"1. Phatak, S.et al.Rheumatology.64, 5, 2525-2532 (2025).ArticlePubMedGoogle ScholarDownload references",d44151-025-00169-0,https://www.nature.com/articles/d44151-025-00169-0,Nature India,2025-09-10,,incremental,2025-09-12T17:52:15,2025-09-12T17:52:15
155,Active use of latent tree-structured sentence representation in humans and large language models,"Understanding how sentences are represented in the human brain, as well as in large language models (LLMs), poses a substantial challenge for cognitive science. Here we develop a one-shot learning task to investigate whether humans and LLMs encode tree-structured constituents within sentences. Participants (totalN= 372, native Chinese or English speakers, and bilingual in Chinese and English) and LLMs (for example, ChatGPT) were asked to infer which words should be deleted from a sentence. Both groups tend to delete constituents, instead of non-constituent word strings, following rules specific to Chinese and English, respectively. The results cannot be explained by models that rely only on word properties and word positions. Crucially, based on word strings deleted by either humans or LLMs, the underlying constituency tree structure can be successfully reconstructed. Altogether, these results demonstrate that latent tree-structured sentence representations emerge in both humans and LLMs.",s41562-025-02297-0,https://www.nature.com/articles/s41562-025-02297-0,Nature Human Behaviour,2025-09-10,,incremental,2025-09-12T17:51:01,2025-09-12T17:51:01
134,Long-range PM2.5pollution and health impacts from the 2023 Canadian wildfires,"Smoke from extreme wildfires in Canada adversely affected air quality in many regions in 20231,2. Here we use satellite observations, machine learning and a chemical transport model to quantify global and regional PM2.5(particulate matter less than 2.5 μm in diameter) exposure and human health impacts related to the 2023 Canadian wildfires. We find that the fires increased annual PM2.5exposure worldwide by 0.17 μg m–3(95% confidence interval, 0.09–0.26 μg m–3). North America had the largest increase in annual mean exposure (1.08 μg m–3; 0.82–1.34 μg m–3), but there were also increases in Europe (0.41 μg m–3; 0.32–0.50 μg m–3) owing to long-range transport. Annual mean PM2.5exposure in Canada increased by 3.82 μg m–3(3.00–4.64 μg m–3). In the USA, the contribution of the Canadian fires to increased PM2.5was 1.49 μg m–3(1.22–1.77 μg m–3), four times as large as the contribution from the 2023 wildfires originating in the USA. We find that 354 million (277–421 million) people in North America and Europe were exposed to daily PM2.5air pollution caused by Canadian wildfires in 2023. We estimate that 5,400 (3,400–7,400) acute deaths in North America and 64,300 (37,800–90,900) chronic deaths in North America and Europe were attributable to PM2.5exposure to the 2023 Canadian wildfires. Our results highlight the far-reaching PM2.5pollution and health burden that large wildfires can have in a single year.",s41586-025-09482-1,https://www.nature.com/articles/s41586-025-09482-1,Nature,2025-09-10,,incremental,2025-09-12T16:52:32,2025-09-12T16:52:32
123,Sampling-enabled scalable manifold learning unveils the discriminative cluster structure of high-dimensional data,"As a pivotal branch of machine learning, manifold learning uncovers the intrinsic low-dimensional structure within complex non-linear manifolds in high-dimensional space for visualization, classification, clustering and gaining key insights. Although existing techniques have achieved remarkable successes, they suffer from extensive distortions of cluster structure, which hinders the understanding of underlying patterns. Scalability issues also limit their applicability for handling large-scale data. Here we propose a sampling-based scalable manifold learning technique that enables uniform and discriminative embedding (SUDE) for large-scale and high-dimensional data. It starts by seeking a set of landmarks to construct the low-dimensional skeleton of the entire data and then incorporates the non-landmarks into the learned space by constrained locally linear embedding. We empirically validated the effectiveness of SUDE on synthetic datasets and real-world benchmarks and applied it to analyse single-cell data and detect anomalies in electrocardiogram signals. SUDE exhibits a distinct advantage in scalability with respect to data size and embedding dimension and shows promising performance in cluster separation, integrity and global structure preservation. The experiments also demonstrate notable robustness in embedding quality as the sampling rate decreases.",s42256-025-01112-9,https://www.nature.com/articles/s42256-025-01112-9,Nature Machine Intelligence,2025-09-10,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
122,Towards agentic science for advancing scientific discovery,"Artificial intelligence is transforming scientific discovery through (semi-)autonomous agents capable of reasoning, planning, and interacting with digital and physical environments. This Comment explores the foundations and frontiers of agentic science, outlining its emerging directions, current limitations, and the pathways for responsible integration into scientific practice. Lindsay, R. K., Buchanan, B. G., Feigenbaum, E. A. & Lederberg, J.Artif. Intell.61, 209–261 (1993).ArticleGoogle ScholarWeizenbaum, J.Commun. ACM9, 36–45 (1966).ArticleGoogle ScholarLeCun, Y., Bengio, Y. & Hinton, G.Nature521, 436–444 (2015).ArticleGoogle ScholarVaswani, A. et al. Preprint athttps://doi.org/10.48550/arxiv.1706.03762(2017).Masterman, T., Besen, S., Sawtell, M. & Chao A. Preprint athttps://doi.org/10.48550/arxiv.2404.11584(2024).Gridach, M., Nanavati, J., Abidine, K. Z. E., Mendes, L. & Mack, C. Preprint athttps://doi.org/10.48550/arxiv.2503.08979(2025).Lu, C. et al. Preprint athttps://doi.org/10.48550/arxiv.2408.06292(2024).Narayanan, S. M. et al. Preprint athttps://doi.org/10.48550/arxiv.2506.17238(2025).Mishra, V. et al. Preprint athttps://doi.org/10.48550/arxiv.2412.09560(2024).Boiko, D. A., MacKnight, R., Kline, B. & Gomes, G.Nature624, 570–578 (2023).ArticleGoogle ScholarSzymanski, N. J. et al.Nature624, 86–91 (2023).ArticleGoogle ScholarChiang, Y., Hsieh, E. Chou, C.-H. & Riebesell, J. Preprint athttps://doi.org/10.48550/arxiv.2401.17244(2024).Kwa, T. et al. Preprint athttps://doi.org/10.48550/arxiv.2503.14499(2025).Yao, S., Shinn, N., Razavi, P. & Narasimhan K. Preprint athttps://doi.org/10.48550/arxiv.2406.12045(2024).Krishnan, N. M. A. et al. Preprint athttps://doi.org/10.48550/arxiv.2501.10385(2024).Download references H.X. acknowledges funding support from the US Department of Energy, Office of Science, Basic Energy Sciences, Chemical Sciences, Geosciences, and Biosciences Division (DE-SC0023323). Authors and AffiliationsDepartment of Chemical Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USAHongliang XinDepartment of Chemical Engineering, Carnegie Mellon University, Pittsburgh, PA, USAJohn R. KitchinDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USAHeather J. KulikAuthorsHongliang XinView author publicationsSearch author on:PubMedGoogle ScholarJohn R. KitchinView author publicationsSearch author on:PubMedGoogle ScholarHeather J. KulikView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorsCorrespondence toHongliang Xin,John R. KitchinorHeather J. Kulik. Competing interestsThe authors declare no competing interests. Peer review informationNature Machine Intelligencethanks Edvin Fako, and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Reprints and permissions Cite this articleXin, H., Kitchin, J.R. & Kulik, H.J. Towards agentic science for advancing scientific discovery.Nat Mach Intell(2025). https://doi.org/10.1038/s42256-025-01110-xDownload citationPublished:10 September 2025DOI:https://doi.org/10.1038/s42256-025-01110-xShare this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s42256-025-01110-x,https://www.nature.com/articles/s42256-025-01110-x,Nature Machine Intelligence,2025-09-10,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
1,August Issue,"Generative drug design opens avenues for discovering novel compounds within the vast chemical space rather than conventional screening against limited libraries. However, the practical utility of the generated molecules is frequently constrained, as many designs prioritize a narrow range of pharmacological properties and neglect physical reliability, which hinders the success rate of subsequent wet-laboratory evaluations. Here, to address this, we propose ED2Mol, a deep learning-based approach that leverages fundamental electron density information to improve de novo molecular generation and optimization. The extensive evaluations across multiple benchmarks demonstrate that ED2Mol surpasses existing methods in terms of the generation success rate and >97% physical reliability. It also facilitates automated hit optimization that is not fully implemented by other methods using fragment-based strategies. Furthermore, ED2Mol exhibits generalizability to more challenging, unseen allosteric pocket benchmarks, attaining consistent performance. More importantly, ED2Mol has been applied to various real-world essential targets, successfully identifying wet-laboratory-validated bioactive compounds, ranging from FGFR3 orthosteric inhibitors to CDC42 allosteric inhibitors, GCK and GPRC5A allosteric activators. The directly generated binding modes of these compounds are close to predictions through molecular docking and further validated via the X-ray co-crystal structure. All these results highlight ED2Mol’s potential as a useful tool in drug design with enhanced effectiveness, physical reliability and practical applicability.",10.1038/s42256-025-01095-7,,Nature Machine Intelligence,2025-09-10,,incremental,2025-09-10T19:28:24,2025-09-10T19:28:24
186,Deep learning based solar forecasting for optimal PV BESS sizing in ultra fast charging stations,"Ultra-fast charging stations (UFCS) present a significant challenge due to their high power demand and reliance on grid electricity. This paper proposes an optimization framework that integrates deep learning-based solar forecasting with a Genetic Algorithm (GA) for optimal sizing of photovoltaic (PV) and battery energy storage systems (BESS). A Gated Recurrent Unit (GRU) model is employed to forecast PV output, while the GA maximizes the Net Present Value (NPV) by selecting optimal PV and BESS sizes tailored to weekday and weekend demand profiles. The results show that PV integration alone improves the NPV by €6.19 million, while combining PV and BESS increases it to €33.97 million. With projected cost reductions, the system achieves a peak NPV of €34.05 million. Reliability analysis using Energy Sufficiency Ratio (ESR) and Autonomy Ratio (AR) confirms enhanced self-sufficiency and reduced grid dependency. This study demonstrates the techno-economic potential of hybrid renewable-powered UFCS using intelligent forecasting and evolutionary optimization.",s41598-025-17408-0,https://www.nature.com/articles/s41598-025-17408-0,Scientific Reports,2025-09-09,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
163,Learning ecosystem-scale dynamics from microbiome data with MDSINE2,"Although dynamical systems models are a powerful tool for analysing microbial ecosystems, challenges in learning these models from complex microbiome datasets and interpreting their outputs limit use. We introduce the Microbial Dynamical Systems Inference Engine 2 (MDSINE2), a Bayesian method that learns compact and interpretable ecosystems-scale dynamical systems models from microbiome timeseries data. Microbial dynamics are modelled as stochastic processes driven by interaction modules, or groups of microbes with similar interaction structure and responses to perturbations, and additionally, noise characteristics of data are modelled. Our open-source software package provides multiple tools for interpreting learned models, including phylogeny/taxonomy of modules, and stability, interaction topology and keystoneness. To benchmark MDSINE2, we generated microbiome timeseries data from two murine cohorts that received faecal transplants from human donors and were then subjected to dietary and antibiotic perturbations. MDSINE2 outperforms state-of-the-art methods and identifies interaction modules that provide insights into ecosystems-scale interactions in the gut microbiome.",s41564-025-02112-6,https://www.nature.com/articles/s41564-025-02112-6,Nature Microbiology,2025-09-09,,incremental,2025-09-12T17:58:09,2025-09-12T17:58:09
154,High-temperature polymer composite capacitors with high energy density designed via machine learning,"Polymer dielectrics are the primary energy storage media in electrostatic capacitors, which are essential components in power electronics for electric vehicles and renewable energy systems. Composite approach has been intensively explored to enhance the energy density (Ud) and breakdown strength (Eb) of polymers at high temperatures, but finding fillers with both a large bandgap (Eg) and high electronic affinity (Ea) remains challenging. Here, assisted by a generative machine learning approach, we discover and synthesize organic fillers of both a largeEg(~5.5 eV) and highEa(~4.5 eV). These fillers enable polyimide composite films to deliver aUdof 5.1 J cm−3at discharge efficiency of 90% and 2 × 105charge–discharge cycles at 250 °C. Moreover, we fabricate high-quality, kilometre-scale composite films using roll-to-roll processing and demonstrate that industrial capacitors incorporating these metalized composite films exhibit stable discharge and self healing in harsh environments.",s41560-025-01863-0,https://www.nature.com/articles/s41560-025-01863-0,Nature Energy,2025-09-09,,incremental,2025-09-12T17:48:49,2025-09-12T17:48:49
153,Sound science,"Passive acoustic monitoring is opening up new opportunities for biodiversity monitoring, but there is still work to do to ensure that it represents a reliable method for biodiversity reporting. Passive acoustic monitoring has emerged as a rapidly expanding tool for biodiversity monitoring, driven by technological developments in sensor technology, data processing and storage, and machine learning-based analysis. As with optical methods in remote sensing, acoustic recorders have the advantage of recording data on multiple taxonomic groups simultaneously, being readily amenable to automated analysis, and capturing data on large temporal and spatial scales without the constraints of a human observer being present. Two studies in this issue ofNature Ecology & Evolutionmake use of these approaches to both quantify biodiversity and track its dynamics through time. In a global analysis, Somervuo et al.placepassive acoustic recorders at natural and urban sites across all continents on Earth except Antarctica, and analyse bioacoustic signatures over a period of up to 3 years. By separately analysing sounds that originate from wildlife and those that originate from human sources, they show that soundscapes from wildlife are highly predictable across temporal scales, and have predictable rhythms that are structured by latitude, seasonality and time of day. However, they find the opposite to be true of anthropogenic soundscapes: not only are human-made sounds less predictable, but also, where patterns do exist, these often conflict with biological rhythms. For example, vehicle noise early in the morning and late in the evening coincides with the dawn and dusk chorus of bird song. Such conflicts for acoustic space on a global scale are of great concern, as they have the potential to mask animal communication. As with light pollution, this disruption of behaviour patterns within anthropogenic landscapes has the potential to exert strong selective pressure on animal populations if these are unable to sufficiently adjust their acoustic signals to increasing levels of urban noise. A second study in this issue demonstrates how acoustic monitoring can be used to augment more traditional biodiversity surveys. In their analysis of the effect of land-use change on avian biodiversity in Colombia, Socolar et al.conductbird surveys using expert observers, but supplement their point counts with sound recordings. They then use these to identify unknown sounds by cross referencing to sound libraries, including the Macaulay Library, a digital archive of natural history media hosted by Cornell Lab of Ornithology. With more than two million recordings, this represents the largest archive of animal media in the world. It is also the reference on which the hugely popular bird identification appMerlinis trained, using computer vision to match audio recordings to spectrograms. This app demonstrates the utility of acoustic species identification for citizen science and engagement with the natural world: more than 11 million people used Merlin to identify bird calls in 2024 alone. Another open archive of wildlife sounds isxeno-canto, now 20 years old, and host to some 700,000 citizen-science-enabled recordings. In a 2021 analysis, Morrison et al. used data from xeno-canto to reconstruct 25 years of soundscapes across Europe and North America, which revealed an alarming decline in acoustic diversity driven by declines in avian species richness1. They argue that such a loss of diverse soundscapes may have profound effects on human well-being, and dilute the quality of human–nature experiences. More than half of the terrestrial biosphere is now estimated to be exposed to high levels of ecological novelty, and shifts in community composition are widespread across the world2. Profound shifts in ecological soundscapes seem likely to become a consequence of these biotic changes. Fortunately, there are initiatives to document this acoustic diversity before it is lost: theVanishing Soundscapes Project, for example, aims to collect acoustic records of ecosystems at threat of being lost, and to create an archive of what they call ‘acoustic fossils’ — among them recordings taken at the exact location in the USA where Aldo Leopold wrote his influential ecological essays collated inA Sand County Almanacin 1949. Despite growing interest in collecting, archiving and analysing bioacoustic data, many challenges still remain before acoustic monitoring may become more widely adopted for long-term biodiversity monitoring. For example, it is no coincidence that much of the work on terrestrial biodiverse soundscape has been conducted on bird vocalizations. Not only are birds conspicuously vocal animals, but there also exists a wealth of archived acoustic data on which to train identification methods: an evaluation of more than 400 validated terrestrial and aquatic soundscape datasets revealed that 44% represented avian recordings, and there were pronounced data gaps among non-human-audible frequencies and subterranean ecosystems3. Adequate data storage for passive acoustic monitoring conducted over many months or years continues to represent a substantial challenge for the broad adoption of acoustic monitoring, as does the ability to accurately identify species in hyperdiverse ecosystems4,5. Indeed, an analysis of more than 8,000 soundscape recordings collected concurrently with manually recorded bird counts across 4 different diverse tropical and temperate ecosystems identified no common acoustic diversity features in biodiverse soundscapes, using both univariate and machine-learning-based classification methods6. Of course, we expect that such methods will continue to improve with advances in artificial intelligence7, but for now expert surveys continue to represent the gold standard. As with other biodiversity monitoring methods from satellite remote sensing to environmental DNA, passive acoustic monitoring represents a promising new tool in the monitoring arsenal, but we are not quite ready to throw out the human element just yet. Morrison, C. A. et al.Nat. Commun.12, 6217 (2021).ArticleCASPubMedPubMed CentralGoogle ScholarKerr, M. R. et al.Nat. Ecol. Evol.9, 589–598 (2025).ArticlePubMedGoogle ScholarDarras, K. F. A. et al.Glob. Ecol. Biogeogr.34, 5 (2025).ArticleGoogle ScholarBradfer-Lawrence, T., Buřivalová, Z. & Dent, D. H.Trends Ecol. Evol.40, 431–435 (2025).ArticleCASPubMedGoogle ScholarSugai, L. S. M. & Costa-Pereira, R.Trends Ecol. Evol.https://doi.org/10.1016/j.tree.2025.07.012(2025).ArticlePubMedGoogle ScholarSethi, S. S. et al.Nat. Ecol. Evol.7, 1373–1378 (2023).ArticlePubMedPubMed CentralGoogle ScholarRasmussen, J. H., Stowell, D. & Briefer, E. F.Science385, 138–140 (2024).ArticleCASPubMedGoogle ScholarDownload references Reprints and permissions Cite this articleSound science.Nat Ecol Evol9, 1531 (2025). https://doi.org/10.1038/s41559-025-02860-yDownload citationPublished:09 September 2025Issue Date:September 2025DOI:https://doi.org/10.1038/s41559-025-02860-yShare this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41559-025-02860-y,https://www.nature.com/articles/s41559-025-02860-y,Nature Ecology & Evolution,2025-09-09,,incremental,2025-09-12T17:47:31,2025-09-12T17:47:31
150,Bias in predictive models for vitreoretinal diseases: ethnic and socioeconomic disparities in artificial intelligence,"The use of artificial intelligence (AI) in vitreoretinal diseases presents a promising avenue for achieving improved outcomes in vitreoretinal diseases. Predictive models are particularly promising in surgical pathology due to their potential to assist with patient selection, risk stratification, and prediction of surgical outcomes. However, as AI technologies have become increasingly incorporated into vitreoretinal surgery, it is crucial to address potential biases, particularly those related to ethnicity, socioeconomic status, and social background. Such biases can significantly impact the performance of AI models, potentially resulting in inequitable healthcare outcomes, particularly for minority or underrepresented groups.AI systems are trained on large datasets, commonly from electronic health records, imaging data, and patient metadata [1]. When these datasets are unrepresentative or biased towards certain groups, the resulting models may perform poorly for individuals from different ethnic, socioeconomic, or geographical backgrounds.",s41433-025-03990-0,https://www.nature.com/articles/s41433-025-03990-0,Eye,2025-09-09,,incremental,2025-09-12T17:20:17,2025-09-12T17:20:17
143,A long noncoding RNA-based serum signature predicts ado-trastuzumab emtansine (T-DM1) treatment benefit in HER2+ metastatic breast cancer patients: a multicenter cohort study,"Ado-trastuzumab is considered a standard treatment for patients with HER2+ metastatic breast cancer (mBC). Current clinical practices do not reliably predict therapeutic outcomes for patients who are refractory to therapy. Long noncoding RNAs (lncRNAs) are emerging as critical regulators of gene expression and therapeutic resistance, and the use of lncRNAs as tumor biomarkers is becoming more common in other diseases. However, whether they may also be used to predict therapy response in HER2+ mBC is unclear. Using lncRNA microarray profiling, we identified 23 differentially expressed lncRNAs in the serum of HER2+ mBC patients with unique responses to trastuzumab-emtansine (T-DM1). Following RT-PCR validation and machine learning-based selection in the training cohort, four lncRNAs were selected to construct the signature panel and used for T-DM1 response prediction. This four-lncRNA signature classifies patients into high- and low-risk groups and significantly and distinctively predicts patient survival. Importantly, identical outcomes were obtained from the two validation cohorts, confirming that the signature accurately predicts the T-DM1 response of HER2+ mBC patients. Integrative analysis demonstrated that this four-lncRNA signature is primarily released by immune and tumor cells and is correlated with immune activity. Our findings indicate that the four-lncRNA signature is a potentially promising biomarker for predicting T-DM1 treatment outcome, as it may reliably predict the T-DM1 treatment response in HER2+ mBC.",s41420-025-02701-8,https://www.nature.com/articles/s41420-025-02701-8,Cell Death Discovery,2025-09-09,,incremental,2025-09-12T17:05:52,2025-09-12T17:05:52
139,Ethical insights into AI-driven caries detection: a scoping review,"BackgroundArtificial Intelligence (AI) has become increasingly integrated into dental diagnostics, particularly for detecting carious lesions. While AI offers benefits such as improved accuracy and efficiency, its use raises important ethical concerns, including transparency, patient privacy, autonomy, diversity and accountability. This scoping review aims to identify these ethical concerns using a structured ethical framework.MethodologyThree databases were searched for papers regarding caries detection using AI. An established ethical framework was used to screen each paper for potential areas of concern.ResultsA total of 351 abstracts were screened, of which 7 articles were included in this review. Each article was screened for established ethical principles including transparency, diversity, wellness, autonomy, privacy, accountability, equity, prudence, sustainable development, solidarity and governance. Diversity was the main ethical concern. Concerns related to accountability, equity and transparency were identified in 2 of the articles whereas ethical issue of privacy was identified in 4 of the articles. Only one study mentioned that no ethical approval was taken prior to commencement of study.ConclusionAI in caries detection faces ethical issues like data bias, privacy risks, and equity concerns, potentially leading to flawed AI models. These issues can be addressed by creating a more specialized ethical framework that is specific to AI in dentistry.Clinical relevanceUnderstanding ethical challenges in AI-driven caries detection is critical to ensure accurate diagnostics, maintain patient trust, protect privacy, and support informed decision-making. Clinicians must be equipped to navigate these challenges as AI tools become more prevalent in dental practice.",s41405-025-00366-0,https://www.nature.com/articles/s41405-025-00366-0,BDJ Open,2025-09-09,,incremental,2025-09-12T16:57:23,2025-09-12T16:57:23
183,Three methods for fair ranking of multiple protected items,"Three approaches to fair ranking in retrieval systems are compared in this paper: mPFR, which is based on the theory of preferences and eigensystems; cRR, which is a simple‘ ’round robin” method; and mMLP, which is based on linear programming. In order to increase fairness without sacrificing retrieval effectiveness, the techniques post-process the rankings that a retrieval system sends back to users. The findings demonstrate that when it comes to protecting elements, mPFR and cRR accomplish the same level of effectiveness and fairness. Despite being computationally more costly than the latter, the former’s mathematical architecture enables the ranking of reordering techniques at various levels of complexity, while mMLP might not be practical for datasets that are too big. Therefore, the choice between these methods often hinges on the specific use case and dataset size, where trade-offs between computational efficiency and desired fairness come into play. Future research could explore optimizing these techniques further to enhance their applicability across diverse scenarios, ensuring that both fairness and effectiveness are maintained.",s41598-025-12735-8,https://www.nature.com/articles/s41598-025-12735-8,Scientific Reports,2025-09-08,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
167,Vessel diameters of 14 basal cerebral arteries assessed in 1000 digital subtraction angiographies,"Angiographic normative values for the size of intracranial vessels are difficult to obtain, since they vary with gender, height and weight. Cerebral angiography only is indicated in severe cerebrovascular diseases, which also can affect cerebral vessel diameters, impeding the definition of physiological values. To approximate “normal” values, over 1000 contemporary cerebral angiographies from a single neurovascular centre were analyzed. Diameters of 14 basal cerebral arteries, age at examination, gender and underlying disease were noted. The dataset (SPSS 29, IBM) comprises 1010 digital subtraction angiographies. For example, a significant difference (p < 0.001) in the size of the left carotid artery between male (3.23 mm, n = 361, sd = 0.49) and female (3.09 mm, n = 645, sd = 0.52) patients is found. The data can be used to compute intraindividual indices in given diseases, e.g. whether an enlarged diameter of the right media, calculated as ratio to the left media or to the ipsilateral carotid artery, is associated to cerebral aneurysms. The dataset allows for training of machine learning programs, e.g. to predict ischemic stroke or cerebral hemorrhage.",s41597-025-05908-7,https://www.nature.com/articles/s41597-025-05908-7,Scientific Data,2025-09-08,,incremental,2025-09-12T18:10:24,2025-09-12T18:10:24
160,Scvi-hub: an actionable repository for model-driven single-cell analysis,"The growing availability of single-cell omics datasets presents new opportunities for reuse, while challenges in data transfer, normalization and integration remain a barrier. Here we present scvi-hub: a platform for efficiently sharing and accessing single-cell omics datasets using pretrained probabilistic models. It enables immediate execution of fundamental tasks like visualization, imputation, annotation and deconvolution on new query datasets using state-of-the-art methods, with massively reduced storage and compute requirements. We show that pretrained models support efficient analysis of large references, including the CZI CELLxGENE Discover Census. Scvi-hub is built within the scvi-tools open-source environment and integrated into scverse. Scvi-hub offers a scalable and user-friendly framework for accessing and contributing to a growing ecosystem of ready-to-use models and datasets, thus putting the power of atlas-level analysis at the fingertips of a broad community of users.",s41592-025-02799-9,https://www.nature.com/articles/s41592-025-02799-9,Nature Methods,2025-09-08,,incremental,2025-09-12T17:57:09,2025-09-12T17:57:09
158,Building the world’s first truly global medical foundation model,"Since 2022, the field of medical artificial intelligence (AI) has begun a shift toward foundation models, machine learning systems that are trained on broad data at scale and are adaptable to a wide range of downstream tasks1,2. Medical foundation models are rapidly evolving, driven by the synergy of expanding medical data repositories, advances in neural network architecture (especially transformers), self-supervised learning approaches and computing power. Medical foundation models are capable of performing, or can be adapted to perform, a range of medical tasks with a minimal amount of annotated data. To date, several promising breakthroughs with foundation models have been demonstrated across diverse medical domains, including pathology, radiology and ophthalmology3,4,5.Nevertheless, training robust medical foundation models requires large, diverse and clinically useful representative data6. Assembling such datasets remains a major challenge for the research community because of strict data-sharing regulations intended to protect patient privacy and ensure ethical compliance. For these reasons, most existing foundational models are trained on datasets that are geographically and demographically ‘narrow’ (that is, not globally representative), limiting their generalizability and effectiveness, particularly in under-represented regions and populations6,7,8.",s41591-025-03859-5,https://www.nature.com/articles/s41591-025-03859-5,Nature Medicine,2025-09-08,,incremental,2025-09-12T17:54:50,2025-09-12T17:54:50
138,Behind the 8-ball," In February 2024, the journalFrontiers in Cell and Developmental Biologypublished a paper entitled ‘Cellular functions of spermatogonial stem cells in relation to JAK/STAT signaling pathway'. The paper itself, unlikely to be of interest to the ordinary person, found a worldwide audience and internet savagery thanks in no small part - and pardon the pun - to a large rat penis. Let me explain. Within the paper, the authors featured a figure of a dissected rat penis which - and I exaggerate not - was more than double the size of its body, while labels in the figure read ‘testtomcels' and ‘dck'. No, unfortunately I will not be re-publishing the image, although a quick search will quickly reveal the girthy small mammal. Unfortunately for the rat community, nature had not found a way; the paper credited the image toMidjourney, a popular generative AI tool. In June this year, the Guardian reported thousands of university students in the UK had been caught misusingChatGPTand other artificial intelligence tools in recent years, while traditional forms of plagiarism showed a marked decline. In the report, a survey of academic integrity violations found almost 7,000 proven cases of cheating using AI tools in 2023-24, equivalent to 5.1 for every 1,000 students. That was up from 1.6 cases per 1,000 in 2022-23. Figures up to May suggested that number will increase again this year to about 7.5 proven cases per 1,000 students - but recorded cases represented the tip of the iceberg, according to experts.1 The news release featured a pertinent observation - that these data highlight ‘a rapidly evolving challenge for universities: trying to adapt assessment methods to the advent of technologies such as ChatGPT and other AI-powered writing tools.' These two items - the first being a specific example of the second - shows how difficult it is to police the use of AI. Our publishing partner, Springer Nature, have made excellent progress in preventing undeclared AI-generated work, firstly developing two new tools to protect research integrity, and secondly donating one such tool this year to the STM Integrity Hub, an industry-wide initiative that supports publishers in ensuring the integrity of their published content. Welcome news indeed, but I can't help but feel publishers, journals and editors are significantly behind the 8-ball when it comes to this topic. Of course, there are obvious warning signs - large rat genitalia aside - we're able to spot. Images of people with six fingers, reams of made-up references, data that do not add up are easy to see, but make no mistake about it, this will not always be the case. As large language models (LLM) digest more and more data, these kinks will eventually be ironed out. Even now, it's almost impossible to identify text within an article that's been generated by AI, and that is a dangerous path for us to be on. The quality of research is already being watered down by the demand to publish quantity rather than quality, and AI opens the door for the market to be flooded by make-believe research to back up the point authors wish to make rather than what their research says, which ultimately will only lead to a detrimental effect on the health of patients. This responsibility is something Co-founders of Kiroku, Hannah Burrow and Jay Shah, discuss in this issue. I found their candid responses to the advantages and disadvantages of AI refreshing; usually adopters of the technology refuse to hear concerns. ‘Clarity and accountability', words used by Burrow, should form the cornerstone of how an individual approaches and uses AI - declarations and being up front about its use is infinitely better than being caught out. Their interview is well-worth a read. Ultimately, publishing, like dentistry and the wider healthcare profession, will need to embrace and work with AI rather than against it at some point. When that point comes and how it manifests is another discussion entirely. Is it miles down the road, or is it around the corner? Those are unknowns at the time of writing, but the direction of travel is not. One day AI will not generate large rat genitalia (unless requested, I suppose), but until then, we must tread carefully down the AI path, fully in the knowledge we are playing catch-up to its abilities, hoping for clarity, accountability and openness needed to make the marriage between healthcare, science and publishing a happy one.◆ Goodier M. Revealed: Thousands of UK university students caught cheating using AI.The Guardian(London) 15 June 2025.Download references Authors and AffiliationsBDJ In Practice, London, United KingdomDavid WestgarthAuthorsDavid WestgarthView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorCorrespondence toDavid Westgarth. Reprints and permissions Cite this articleWestgarth, D. Behind the 8-ball.BDJ In Pract38, 284 (2025). https://doi.org/10.1038/s41404-025-3262-8Download citationPublished:08 September 2025Issue Date:08 September 2025DOI:https://doi.org/10.1038/s41404-025-3262-8Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41404-025-3262-8,https://www.nature.com/articles/s41404-025-3262-8,BDJ In Practice,2025-09-08,,incremental,2025-09-12T16:56:55,2025-09-12T16:56:55
137,Is dental education becoming too focused on technology at the expense of hands-on skills?,"The pace of technological change in dentistry is impressive. Digital scanning, 3D printing, virtual simulation, artificial intelligence - what once seemed futuristic is now routine in many dental schools. These advances are changing how we teach, how students learn, and ultimately, how dentistry is practised.However, as we continue to integrate more technology into dental education, a question is being asked with increasing frequency: Are we prioritising digital skills at the expense of hands-on experience?",s41404-025-3214-3,https://www.nature.com/articles/s41404-025-3214-3,BDJ In Practice,2025-09-08,,incremental,2025-09-12T16:56:55,2025-09-12T16:56:55
136,"‘ The key is to be bold, adaptable, and committed to continuous learning as technology evolves'","BDJ In Practicespoke toDr Leanne Branton, owner of Southside Dental Care, to discuss her path to unlocking profitability with digital dentistry.  LBI'd describe it as both exciting and challenging - a journey with real highs but also some bumps along the way. The biggest thing I see, and what I experienced myself, is that many people tend to overthink the move to digital. We spend so much time weighing up ‘is now the right time?' or ‘what if it doesn't work?' that we paralyse ourselves. I was guilty of that too. In reality, adopting digital isn't about waiting for the perfect moment or having every tiny detail mapped out in advance. Like a parachute, it only opens once you've actually jumped. For me, taking that leap of faith changed everything. Yes, there were teething problems and a learning curve, but the rewards far outweighed the challenges. Embracing digital was the catalyst that allowed us to transform from a three-surgery NHS practice into an eight-surgery centre of excellence. Looking back, I'm glad I didn't let the fear of ‘what if' hold me back. The key is to trust the process, surround yourself with good mentorship and support, and have faith that you'll learn and adapt along the way.  LBIt's now pretty standard to see digital tools like scanners embedded in UK dental practices, and most clinics have taken that leap. But in-house manufacturing - such as 3D printing and chairside milling - is still in its infancy for many practices. That's the step that truly unlocks profitability, streamlines workflows, and will become essential as we face a growing dental technician shortage.©tommy/DigitalVision Vectors/Getty Images Plus  LBDigital dentistry is no longer a luxury because it can directly impact the efficiency and the bottom line of any modern practice. By digitising workflows, we open up the door to shortening treatment times, reducing errors, and cutting down on lab costs. This efficiency means more patients can be seen, and with greater accuracy, leading to higher quality outcomes and increased patient satisfaction - which can all feed back into practice growth and profitability. In today's environment, with rising costs and a shortage of skilled dental technicians, relying solely on traditional methods isn't as sustainable. Practices that invest in digital solutions - especially in-house manufacturing - are able to work faster, adapt more easily to challenges, and maximise revenue from both NHS and private work. Ultimately, digital isn't just about keeping up with technology; it's become central for practices that want to thrive, stay competitive, and remain resilient in the years ahead. ‘ In the current climate, I believe embracing digital is less about the type of practice and more about future-proofing your business and responding to what patients now expect, regardless of how your services are funded.' LBDigital dentistry absolutely transcends the different models of UK dental practice - whether NHS, mixed, or private. The benefits of digital workflows, like increased efficiency, improved accuracy, and better patient experience, are universal and not limited to one type of provision. ‘ In the current climate, I believe embracing digital is less about the type of practice and more about future-proofing your business and responding to what patients now expect, regardless of how your services are funded.' In fact, with the pressures facing all sectors, be it the time constraints of NHS work or the high expectations of private patients, digital tools help level the playing field. They allow NHS practices to operate more efficiently and provide a higher standard of care, while also giving private and mixed practices the capacity to offer advanced and bespoke treatments. If anything, digital dentistry should be accessible across all models, as it's an optimal way for delivering consistent, high-quality care. In the current climate, I believe embracing digital is less about the type of practice and more about future-proofing your business and responding to what patients now expect, regardless of how your services are funded.  LBWhile the UK is making great strides in digital dentistry adoption, it still lags somewhat behind certain European counterparts who have been quicker to fully integrate digital workflows, especially in-house manufacturing and AI-driven diagnostics. That said, the gap is closing rapidly as UK practices increasingly recognise the clear business and clinical benefits of going digital. In some European countries, streamlined regulatory frameworks and strong incentives for digital innovation have accelerated adoption. However, the UK dental sector is now catching up fast, with growing investments in advanced scanning, CAD/CAM, and 3D printing technologies. The challenge remains not just acquiring digital tools but integrating them strategically into practice workflows to maximise efficiency and patient outcomes.  LBMy advice would be to start with a clear vision but avoid getting stuck in analysis paralysis. Don't wait until every detail is perfect - take that leap and embrace the learning curve. Digital dentistry is a journey, not a switch you flip overnight. Focus on investing in the right technology that aligns with your practice goals, but equally important is training your team to use it confidently and efficiently. Surround yourself with mentors or peers who have walked the path; their insights can save you time and mistakes. Most importantly, remember that digital tools are there to enhance patient care and streamline workflows. Keep that patient-centric mindset front and centre, and the profitability and growth will follow naturally. The key is to be bold, adaptable, and committed to continuous learning as technology evolves.  LBAbsolutely, it's an incredibly exciting time to be entering the dental profession. We're at the start of a major growth curve - often called an S-curve - where technology is rapidly evolving and transforming how we deliver care. This creates amazing opportunities for new dentists to work with cutting-edge tools like digital scanning, 3D printing, AI diagnostics, and more. The pace of innovation is opening up new possibilities, from enhancing treatment precision to supporting the development of streamlined and sustainable practice models. For those willing to embrace and adapt to these changes, the potential for professional growth, improved patient outcomes, and practice success has never been greater. Dr Branton will be presenting ‘Unlocking Profitability with Digital Dentistry' at DS World in Birmingham on Saturday 11 October at 15:30-16:00. For more information and to register visithttps://www.dentsplysirona.com/en-gb/lp/ds-world.html.◆ BioDr. Leanne Branton is an experienced implant dentist, educator, and mentor based in Edinburgh. She owns a leading multidisciplinary specialist practice and holds a Diploma in Implant Dentistry from the Royal College of Surgeons in London. Passionate about digital technology, she focuses on achieving exceptional aesthetic outcomes.Beyond clinical practice, Dr. Branton mentors dentists through the Platinum Implant Programme, an advanced training course in Edinburgh. She is also the founder of Diamond Smiles Foundation, a charity providing free dental transformations for women who have survived domestic abuse, helping restore their health and confidence. Authors and AffiliationsBDJ In Practice, London, United KingdomDavid WestgarthAuthorsDavid WestgarthView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorCorrespondence toDavid Westgarth. Reprints and permissions Cite this articleWestgarth, D. ‘ The key is to be bold, adaptable, and committed to continuous learning as technology evolves'.BDJ In Pract38, 288–289 (2025). https://doi.org/10.1038/s41404-025-3267-3Download citationPublished:08 September 2025Issue Date:08 September 2025DOI:https://doi.org/10.1038/s41404-025-3267-3Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41404-025-3267-3,https://www.nature.com/articles/s41404-025-3267-3,BDJ In Practice,2025-09-08,,incremental,2025-09-12T16:56:55,2025-09-12T16:56:55
135,‘AI is absolutely a friend when used responsibly',"BDJ In Practicespoke toHannah BurrowandJay Shah, Co-founders of Kiroku, to discuss all things artificial intelligence.  JSAI's clearest win so far is taking routine, time-heavy work off clinicians' shoulders. Real-time, AI-powered note-taking systems now transcribe, structure and code clinical records as we speak, so the dentist can concentrate on the patient instead of the keyboard. Because the notes are generated consistently and mapped to standard terminologies, compliance checks, referrals and audits run faster too. For individual practitioners, that means less cognitive load, the chance to leave on time, and if they wish, finishing any remaining admin from home rather than staying late in the surgery. AI is also becoming a reliable second pair of eyes in diagnosis. Image analysis tools that highlight early dental caries, infection around tooth roots or the first signs of gum disease are already embedded in many practice management systems, providing immediate feedback while the radiograph is still on screen. HBEqually tangible and very patient-facing is the latest generation of AI-assisted intraoral scanners. As the wand moves around the mouth, the software builds and refines a 3D model in real time, automatically cleaning up artefacts and suggesting preparation margins. Patients can literally watch their own teeth appear on the monitor, which is a powerful aid to communication and treatment acceptance. Taken together, these technologies standardise data capture, speed up clinical and administrative workflows, and make expertise more scalable across a group of practices. The result is a positive cascade: practices run more efficiently, dentists enjoy a lighter workload and better work-life balance, and patients receive more personalised, dependable care with fewer surprises and shorter chairside times.  JSThe chief risk is over-reliance on technology without understanding its limits. AI systems are trained on data that is often fragmented, inconsistent or biased; if those flaws creep into the model, they can lead to missed or incorrect diagnoses. Another danger is the ‘black box' problem. If the algorithm's reasoning is opaque, the dentist cannot justify a clinical decision to a patient, undermining both professional judgment and trust. HBExpectation management matters here. People increasingly assume that ‘AI' equals perfection, yet these tools are iterative: models are constantly updated and refined, and in many cases, improving. Clinicians and patients alike need to treat today's output as a best-available estimate, not gospel truth, and be prepared for results (and user interfaces) to evolve with time. Data privacy adds another layer. Dental records are deeply personal, and every AI vendor must meet stringent standards for security, auditability and regulatory compliance, especially as new entrants with little healthcare heritage appear. In short, AI should augment, not replace, human expertise. The danger arises when it becomes a shortcut: when clinicians skip the contextual, empathetic elements of care or delegate final judgment to software that is still a moving target.  JSOne of the most significant areas of progress has been in efficiency and documentation. AI-driven clinical note generation has accelerated rapidly. Systems can now listen in real time, transcribe, structure, and in some cases, even code the clinical encounter. This allows dentists to finish appointments with a complete, standards-compliant record instead of a backlog of unfinished notes. The gains are tangible: minutes saved per patient, fewer late nights, and a substantial reduction in repetitive admin. Diagnostics have also come a long way, particularly in tools that clinicians can use directly with patients. Deep-learning algorithms that analyse radiographs have become a reliable safety net, highlighting subtle caries, early periapical lesions or crestal bone loss that tired eyes might miss. Many platforms now overlay colour-coded markers directly onto the x-ray, allowing the dentist to point to the screen and say, ‘Here's what I'm concerned about' - making the diagnosis more concrete and easier for the patient to understand. HBAnother major shift has occurred in visualisation within the mouth. AI-assisted intraoral scanners have evolved from novelty to near-standard tools in restorative dentistry. As the scanning wand moves, the software builds and refines a 3D model in real time, removing artefacts and even suggesting margin lines within seconds. Being able to show patients a live, rotatable model of their teeth makes issues like cracks, wear facets or crowding instantly obvious, often communicating more clearly than words or flat 2D images ever could. Communication with patients is also being transformed. Large language models are now being used to generate personalised post-operative instructions, translate explanations automatically, and deliver behaviour-change nudges in plain language. Instead of receiving a generic leaflet, patients can now get a tailored message that refers to their specific restoration, their next hygiene visit, and even includes an image from their scan - boosting understanding, trust and long-term adherence. Taken together, these advances represent a real shift from experimental prototypes to practical, everyday tools. They streamline practice operations, strengthen diagnostic confidence and, perhaps most importantly, open a window that lets patients see what the dentist sees.  HBThere's certainly a spectrum of enthusiasm, caution and resistance toward AI, but it splits more by mindset and available time than by age. Younger clinicians, used to apps and instant feedback, are often more comfortable investing time upfront to customise templates or settings. With support from onboarding teams, they quickly see the payoff in shorter appointments and fewer late-night admin sessions. Across all age groups, you also find time-pressed pragmatists: dentists who'll adopt any tool that clearly saves minutes, as long as the setup is simple and the support is there. The difference isn't age, it's bandwidth and trust that the benefit will be immediate. JSSceptics often raise concerns about de-skilling, compliance or data privacy. But when AI offers transparency, like showing why it flagged a lesion, and gives clinicians clear editorial control, attitudes shift. Many who were initially resistant soften once AI is built quietly into the software they already use. When it becomes a feature, not a buzzword, objections fade. Institutional silence or, on the other hand, recommendations without consulting the experts in the field can amplify anxiety. That's why regulators, educators and providers like the GDC, HEE and NHS need to engage with providers as well as users regularly and early. If the profession co-designs standards for safety and accountability, we can shape these tools from the ground up. While age affects tech familiarity, the real drivers of adoption are time, trust, and transparent support. With the right approach, enthusiasm for AI can span every generation.  HBOne of the ripest areas for AI integration is still clinical documentation and admin support. Dentistry is full of repetitive, time-consuming tasks; notetaking, formfilling, referral letters, triaging medical histories, that take up clinical time. AI can meaningfully reduce this burden, freeing clinicians to focus on patient care. There's likewise huge potential in personalised patient communication. Language models can tailor treatment plans, reminders and explanations to a patient's reading level or preferred language, boosting understanding and trust, especially for those with different communication needs. JSOn the clinical side, decision support tools such as radiograph analysis, charting aids and risk prediction algorithms are becoming more robust. The real test is integrating them so they enhance, rather than override, professional judgment. The hazards cluster around opacity, bias and data stewardship is one area that all AI models need to get better at. Blackbox systems that cannot justify their suggestions erode confidence, invite legal risk and weaken patient trust. At the same time, largescale data collection demands clear safeguards on privacy, consent and equitable model performance. Ultimately, AI in dentistry must be assistive, transparent and ethically grounded, not merely impressive on paper.  JSWe use AI across the business, not just in the product itself. It's part of how we build, operate and support our customers. Our product and engineering teams use AI to design and develop faster, but also more creatively. Whether it's generating UI concepts, automating testing, or rapidly iterating on prototypes, AI helps us move from idea to implementation at speed. This acceleration means we can build and ship high-quality features much faster than would have been possible even a year ago. It helps us maximise the impact of our team, delivering more value faster, without compromising on quality or creativity. HBOperationally, we use AI to automate repetitive admin tasks, streamline internal processes and reduce cognitive load for the team just as we do for clinicians. And on the customer side, AI helps us understand users better: surfacing common pain points, tailoring support, and delivering more timely, relevant help. Ultimately, AI helps us stay agile, lean and focused on what matters - giving clinicians better tools, faster, and making their working lives easier.  JSAI is absolutely a friend when used responsibly. Like any powerful tool, its value depends on how it's designed, implemented and used. When developers build with clinical context, transparency and safety in mind, and when clinicians treat AI as an aid rather than a crutch, it becomes a force multiplier: saving time, improving accuracy, and enhancing patient care. HBBut it can become a foe if misused. For developers, that means building black-box tools without clinician oversight, prioritising speed over rigour, or treating sensitive health data carelessly. For users, the danger lies in over-reliance: trusting outputs blindly, skipping critical thinking, or assuming AI can replace rather than support professional judgement. The best results come when both sides embrace AI with clarity and accountability. If we build it thoughtfully and use it wisely, it's not just a friend - it's an essential partner in modern dentistry.◆ BiosJay Shah studied Natural Language Processing and Machine Learning at the University of Cambridge. Following his education, Jay co-founded Kiroku and assumed the role of Chief Technology Officer, driving the company's vision and technological advancements forward. Leveraging his expertise in NLP and ML, he has been instrumental in steering Kiroku towards pioneering solutions in the realm of language technology.Dr Hannah Burrow is the CEO and co-founder of Kiroku. Kiroku uses AI to automate the least rewarding parts of a clinician's workload. Before Kiroku, dental professionals spent 25% of their day writing clinical notes. Kiroku has now helped thousands of clinicians save time and provide better care. Prior to starting Kiroku, she worked as a dentist, having had roles in practices, hospitals, and Public Health England. Authors and AffiliationsBDJ In Practice, London, United KingdomDavid WestgarthAuthorsDavid WestgarthView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorCorrespondence toDavid Westgarth. Reprints and permissions Cite this articleWestgarth, D. ‘AI is absolutely a friend when used responsibly'.BDJ In Pract38, 290–291 (2025). https://doi.org/10.1038/s41404-025-3257-5Download citationPublished:08 September 2025Issue Date:08 September 2025DOI:https://doi.org/10.1038/s41404-025-3257-5Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41404-025-3257-5,https://www.nature.com/articles/s41404-025-3257-5,BDJ In Practice,2025-09-08,,incremental,2025-09-12T16:56:55,2025-09-12T16:56:55
121,Accelerating protein engineering with fitness landscape modelling and reinforcement learning,"Protein engineering holds substantial promise for designing proteins with customized functions, yet the vast landscape of potential mutations versus limited laboratory capacity constrains the discovery of optimal sequences. Here, to address this, we present the μProtein framework, which accelerates protein engineering by combining μFormer, a deep learning model for accurate mutational effect prediction, with μSearch, a reinforcement learning algorithm designed to efficiently navigate the protein fitness landscape using μFormer as an oracle. μProtein leverages single-mutation data to predict optimal sequences with complex, multi-amino-acid mutations through its modelling of epistatic interactions and a multi-step search strategy. In addition to strong performance on benchmark datasets, μProtein identified high-gain-of-function multi-point mutants for the enzyme β-lactamase, surpassing one of the highest-known activity levels, in wet laboratory, trained solely on single-mutation data. These results demonstrate μProtein’s capability to discover impactful mutations across the vast protein sequence space, offering a robust, efficient approach for protein optimization.",s42256-025-01103-w,https://www.nature.com/articles/s42256-025-01103-w,Nature Machine Intelligence,2025-09-08,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
120,Conditional generation of real antigen-specific T cell receptor sequences,"Despite recent advances in T cell receptor (TCR) engineering, designing functional TCRs against arbitrary targets remains challenging due to complex rules governing cross-reactivity and limited paired data. Here we present TCR-TRANSLATE, a sequence-to-sequence framework that adapts low-resource machine translation techniques to generate antigen-specific TCR sequences against unseen epitopes. By evaluating 12 model variants of the BART and T5 model architectures, we identified key factors affecting performance and utility, revealing discordances between these objectives. Our flagship model, TCRT5, outperforms existing approaches on computational benchmarks, prioritizing functionally relevant sequences at higher ranks. Most significantly, we experimentally validated a computationally designed TCR against Wilms’ tumour antigen, a therapeutically relevant target in leukaemia, excluded from our training and validation sets. Although the identified TCR shows cross-reactivity with pathogen-derived peptides, highlighting limitations in specificity, our work represents the successful computational design of a functional TCR construct against a non-viral epitope from the target sequence alone. Our findings establish a foundation for computational TCR design and reveal current limitations in data availability and methodology, providing a framework for accelerating personalized immunotherapy by reducing the search space for novel targets.",s42256-025-01096-6,https://www.nature.com/articles/s42256-025-01096-6,Nature Machine Intelligence,2025-09-08,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
119,Towards compute-efficient Byzantine-robust federated learning with fully homomorphic encryption,"In highly regulated domains such as finance and healthcare, where stringent data-sharing constraints pose substantial obstacles, federated learning (FL) has emerged as a transformative paradigm in distributed machine learning, facilitating collaborative model training, preserving data decentralization and upholding governance standards. Despite its advantages, FL is vulnerable to poisoning attacks during central model aggregation, prompting the development of Byzantine-robust FL systems that use robust aggregation rules to counter malicious attacks. However, neural network models in such systems are susceptible to unintentionally memorizing and revealing individual training instances, thereby introducing substantial information leakage risks, as adversaries may exploit this vulnerability to reconstruct sensitive data through model outputs transmitted over the air. Existing solutions fall short of providing a viable Byzantine-robust FL system that is completely secure against information leakage and is computationally efficient. To address these concerns, we propose Lancelot, an efficient and effective Byzantine-robust FL framework that uses fully homomorphic encryption to safeguard against malicious client activities. Lancelot introduces a mask-based encrypted sorting mechanism that overcomes the limitations of multiplication depth in ciphertext sorting with zero information leakage. It incorporates cryptographic enhancements like lazy relinearization, dynamic hoisting and GPU acceleration to ensure practical computational efficiency. Extensive experiments demonstrate that Lancelot surpasses existing approaches, achieving a 20-fold enhancement in processing speed.",s42256-025-01107-6,https://www.nature.com/articles/s42256-025-01107-6,Nature Machine Intelligence,2025-09-08,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
149,Clinical exome sequencing efficacy and phenotypic expansions involving non-isolated congenital anomalies of kidney and urinary tract (CAKUT+),"Congenital Anomalies of Kidney and Urinary Tract (CAKUT) can occur in isolation or in conjunction with one or more non-CAKUT associated congenital anomalies or neurodevelopmental disorders (CAKUT+). A molecular cause is not identified in most individuals with CAKUT+. This is due, in part, to uncertainty regarding the efficacy of genetic testing and an incomplete understanding of the genes that cause CAKUT+. Here, we use data from 515 individuals with CAKUT+ (n= 500) or isolated CAKUT (n= 15) to determine the efficacy of clinical exome sequencing (cES) and to identify new phenotype expansions that involve CAKUT. We determined that cES established a molecular diagnosis in 27.4% (141/515) of individuals in this cohort. No statistically significant difference in efficacy was seen with regards to age, sex, CAKUT phenotype, or associated organ system abnormality. Only 3.5% (5/144) to 14.6% (21/144) of the individual diagnoses made in our cohort could have been identified using one of four clinically available CAKUT gene panels. We then used a machine-learning approach to confirm thatPHIPis a CAKUT gene and to implicateADNPandSETD5genes associated with an increased risk of CAKUT. These findings lead us to conclude that cES should be considered in individuals with CAKUT+ for whom a molecular diagnosis has not been identified, that cES has the potential to identify many diagnoses in individuals with CAKUT+ that would be missed using a CAKUT gene panel, and that individuals withADNP-,PHIP-, andSETD5-related disorders may present with CAKUT phenotypes.",s41431-025-01929-3,https://www.nature.com/articles/s41431-025-01929-3,European Journal of Human Genetics,2025-09-06,,incremental,2025-09-12T17:16:38,2025-09-12T17:16:38
193,Dopamine as a teaching signal: understanding its role in shaping individual behavior,"In a recent publication inCell, Liebana and colleagues demonstrate that dopamine acts as a circuit-specific teaching signal, shaping individual learning trajectories over time. These reward prediction error (RPE) signals refine behavior by selectively reinforcing neural pathways, revealing a key mechanism through which dopamine guides personalized learning strategies beyond classical reward-based models.1 Dopamine is traditionally known for encoding reward prediction errors, a core component in short-term learning2(e.g., behavioral fine-tuning). However, this classical framework does not fully explain the complexity and individuality of long-term skill acquisition. Real-world learning tasks, such as playing a musical instrument or mastering a sport, often unfold over extended timescales and involve distinct, strategy-dependent phases that vary across individuals. Meanwhile, traditional reinforcement learning (RL) models, which rely on fixed state representations and global value updates, fail to capture such strategic diversity. Similarly, most neuroscience studies have emphasized expert performance rather than the developmental processes that lead to expertise, leaving a critical gap in our understanding of long-term learning trajectories. Liebana et al. outlined a dynamic role for dopamine, particularly within the dorsolateral striatum (DLS),3in shaping individualized long-term learning.1Using longitudinal behavioral tracking and real-time dopamine measurements, the authors explained how dopaminergic signals evolve throughout learning. Initially, dopamine signals reflect reward outcomes, consistent with classical RPEs. However, as training progresses, the signals gradually shift toward task-relevant stimuli in a manner dependent on the animals’ early behavioral biases and subsequent diverse solution strategies. These biases lead to strategy-specific dopamine dynamics: asymmetric activity in one-sided learners and symmetrical patterns in balanced learners. Importantly, dopamine encoded stimulus-choice associations contingent on the internal learning state of each animal, rather than the learned value of the stimulus as in traditional RL models. The learning paradigm involved training mice on a visual decision-making task over several weeks. In each trial, the mice were required to turn a wheel to the clockwise or anticlockwise, depending on the location of a visual grating stimulus. The task structure was held constant throughout training, allowing researchers to isolate internally driven learning processes. Behavioral analyses revealed substantial strategic variability: while some mice developed balanced stimulus–response mappings, others adopted highly lateralized strategies, consistently associating one stimulus side with reward and not the other. Notably, early behavioral biases reliably predicted the eventual psychometric performance curve for each animal across the learning phases. Despite following different trajectories, most animals converged on comparable final performance levels, suggesting that diverse structured and optimized strategies can emerge through consistent experience. To assess the causal role of DLS dopamine in shaping these strategies, the researchers performed optogenetic manipulations during the training period. Inhibition of dopamine release impaired the formation of steep psychometric slopes and stimulus-guided decision-making, despite intact motor execution and sustained task engagement. In a separate experiment, stimulating dopamine in expert one-sided animals following incorrect choices modulated subsequent behavior, only when the animal had used the corresponding stimulus to guide its choice. Conversely, stimulation had no effect when the stimulus was irrelevant to the decision. These findings indicate that dopamine in the DLS serves as a stimulus-contingent teaching signal, and that is engaged selectively when a stimulus is utilized for decisions. In contrast to classical RPEs, which update value representations independent of behavioral context, this dopaminergic signal operates in a more targeted, stimulus- and strategy-specific manner. To computationally model these findings, they developed a biologically inspired deep RL framework, the Tutor–Executor model. This architecture comprises parallel pathways for sensory and contextual information, incorporating three forms of RPEs. Crucially, the model implements partial, input-specific RPEs, updating only the connections associated with either sensory or contextual inputs, recapitulating the DLS dopamine selectivity observed experimentally. The Tutor–Executor model successfully reproduced key behavioral features observed in mice, such as asymmetric slope development, early behavioral biases, asymmetric slope development and the diverse yet systematic learning trajectories across mice. Dopamine-like signals derived from the learning gradients in the model closely matched the dynamics of recorded DLS dopamine release. Further analysis of the model revealed that transitions between strategies were governed by unstable saddle points in the weight space. These saddle points created temporary learning plateaus, which helped explain why some animals stalled at intermediate learning stages. The model also captured a gradual shift from cortical to subcortical control over time, aligning with biological transitions from goal-directed to habitual behavior. This study builds on the classical view that dopamine merely encodes RPEs and proposes a broader, more dynamic role in guiding individualized long-term learning. By tracking mice over several weeks during a visual decision-making task, the authors uncovered diverse and structured learning strategies determined by early biases. Dopamine release in the DLS evolved alongside these behavioral shifts, encoding not just reward-based but also strategy-dependent stimulus-choice associations that anticipated future transitions. These signals were causally required for effective strategy formation, operating selectively when animals engaged with decision-relevant information. This research formulates new directions in neuroscience by highlighting dopamine as a stimulus-contingent teaching signal rather than a global reinforcer. Nonetheless, other brain regions rich in dopaminergic inputs remain to be explored. The RPE model employed in this study can also be extended to other neurotransmission systems involved in associative and reinforcement learning, such as glutamatergic and GABAergic (gamma-aminobutyric acid) circuits, offering broader insights into large-scale learning mechanisms.4Moreover, the Tutor–Executor computational model provides a biologically plausible framework for understanding how partial, input-specific RPEs shape strategy development and adaptive behavior. These findings may broaden the scope of application beyond fundamental neuroscience. The model can provide insights into disorders and diseases relevant to reward-driven behavioral motivations, such as addiction, depression, or schizophrenia, as well as those involving dopaminergic signalings, including Parkinson’s disease, attention deficit/hyperactivity disorder, or obsessive-compulsive disorder. Moreover, the model enables disease prediction and therapeutic strategies based on individual behavioral and dopaminergic trajectories. The principles can also inform deep RL models in artificial intelligence (AI), enhancing decision-making and error correction through feedback, mirroring the brain’s mechanisms.5Such AI-based models could deliver personalized experiences in education, training, and daily decision-making, even suggesting music to match the mood of the individual. Together, these findings on DLS dopaminergic signaling and the “Tutor–Executor” model will enhance our understanding of how we perceive and adapt to the world, highlighting how insights into the brain’s learning mechanisms can teach us the optimization of learning strategies in animals, humans and AI models (Fig.1).Fig. 1A schematic overview of the role of dopamine in individualized long-term learning (Created and modified using BioRender.com license no:SV28KABRLC). Recent work by Liebana et al. demonstrates that, unlike traditional reinforcement learning (RL) models based on value updating with fixed state representations, mice trained on a visual decision-making task developed diverse and structured behavioral strategies, ranging from balanced to strongly biased. Dopamine release in the dorsolateral striatum (DLS) evolved in parallel with these behavioral patterns, encoding stimulus-choice associations in a strategy-dependent manner. Optogenetic manipulations confirmed the causal role of DLS dopamine in guiding strategy formation, specifically when animals were actively engaged with task-relevant stimuli. To model these observations, the authors proposed a biologically inspired Tutor–Executor neural network model that incorporates partial, input-specific reward prediction errors (RPEs), successfully capturing both behavioral and neural dynamics. These findings position dopamine as a stimulus-contingent teaching signal, providing a foundation for future studies to explore similar mechanisms in other brain regions, neuromodulatory systems, and learning contexts. Moreover, this work advances our understanding of neurological and psychiatric disorders associated with dopaminergic signaling and reward-driven behavior, offering both predictive and therapeutic insights. Finally, the principles uncovered here may also inform the development of personalized and adaptive decision-making technologies in artificial intelligence (AI)Full size image Liebana, S. et al. Dopamine encodes deep network teaching signals for individual learning trajectories.Cell188, 3789–3805.e33 (2025).ArticlePubMedCASGoogle ScholarSchultz, W., Dayan, P. & Montague, P. R. A neural substrate of prediction and reward.Science275, 1593–1599 (1997).ArticlePubMedCASGoogle ScholarBromberg-Martin, E. S., Matsumoto, M. & Hikosaka, O. Dopamine in motivational control: rewarding, aversive, and alerting.Neuron68, 815–834 (2010).ArticlePubMedPubMed CentralCASGoogle ScholarAmo, R., Uchida, N. & Watabe-Uchida, M. Glutamate inputs send prediction error of reward, but not negative value of aversive stimuli, to dopamine neurons.Neuron112, 1001–1019.e6 (2024).ArticlePubMedPubMed CentralCASGoogle ScholarRichards, B. A. et al. A deep learning framework for neuroscience.Nat. Neurosci.22, 1761–1770 (2019).ArticlePubMedPubMed CentralCASGoogle ScholarDownload references This work was supported by a National Research Foundation of Korea grant (RS-2024-00408736). Author notesThese authors contributed equally: Seung Chan Kim, Sehwan KimAuthors and AffiliationsBrain Science and Engineering Institute, Kyungpook National University, Daegu, KoreaSeung Chan Kim, Sehwan Kim & Sang Ryong KimSchool of Life Science and Biotechnology, BK21 FOUR KNU Creative BioResearch Group, Kyungpook National University, Daegu, KoreaSehwan Kim & Sang Ryong KimAuthorsSeung Chan KimView author publicationsSearch author on:PubMedGoogle ScholarSehwan KimView author publicationsSearch author on:PubMedGoogle ScholarSang Ryong KimView author publicationsSearch author on:PubMedGoogle ScholarContributionsS.R.K. conceptualized the manuscript; S.C.K., S.K., and S.R.K. wrote the original draft; S.C.K. and S.K. created the figure; All authors reviewed and approved the final figure and manuscript.Corresponding authorCorrespondence toSang Ryong Kim. Competing interestsThe authors declare no competing interests. Publisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visithttp://creativecommons.org/licenses/by/4.0/.Reprints and permissions Cite this articleKim, S.C., Kim, S. & Kim, S.R. Dopamine as a teaching signal: understanding its role in shaping individual behavior.Sig Transduct Target Ther10, 283 (2025). https://doi.org/10.1038/s41392-025-02406-5Download citationReceived:15 July 2025Revised:29 July 2025Accepted:19 August 2025Published:05 September 2025DOI:https://doi.org/10.1038/s41392-025-02406-5Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41392-025-02406-5,https://www.nature.com/articles/s41392-025-02406-5,Signal Transduction and Targeted Therapy,2025-09-05,,incremental,2025-09-12T18:17:18,2025-09-12T18:17:18
182,Hybrid manta ray foraging and sine cosine algorithm for managing power transmission congestion influenced by wind energy,"This research work proposes a hybrid Manta ray Forging Optimization- Sine Cosine Algorithm (MRFO-SCA) for Congestion Management (CM) that addresses the power system transmission line congestion cost challenges with the integration of Wind Energy System (WES). The proposed method focuses on two key objectives: first, identifying the most influential bus within the power system using the Bus Sensitivity Factor (BSF) to optimally place a wind power source, thereby impacting the power flow in overloaded lines. Second, MRFO-SCA has been developed for optimal power rescheduling of the generators to alleviate congestion while minimizing the congestion cost. The hybrid MRFO-SCA has been formulated by integrating SCA into the MRFO that enhances the exploration and exploitation phases in MRFO leading to the rapid discovery of the global optima. MRFO-SCA has been verified on benchmark functions that have delivered appreciable results. The effectiveness of the proposed approach has been assessed and validated using the IEEE-30 bus system. Simulation results indicate that incorporating WES with MRFO-SCA has led to a reduction in congestion costs by 18.45%, 15.68%, 10.34%, 9.72%, 5.46%, and 1.57% as compared to several recent optimization techniques. A comparative evaluation demonstrates that MRFO-SCA outperforms other methods in terms of congestion cost reduction, system loss minimization, bus voltage improvement, faster convergence, and reduced computational time, making it a more efficient and accurate solution for CM.",s41598-025-13988-z,https://www.nature.com/articles/s41598-025-13988-z,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
181,Benchmarking feature projection methods in radiomics,"In radiomics, feature selection methods are primarily used to eliminate redundant features and identify relevant ones. Feature projection methods, such as principal component analysis (PCA), are often avoided due to concerns that recombining features may compromise interpretability. However, since most radiomic features lack inherent semantic meaning, prioritizing interpretability over predictive performance may not be justified. This study investigates whether feature projection methods can improve predictive performance compared to feature selection, as measured by the area under the receiver operating characteristic curve (AUC), the area under the precision-recall curve (AUPRC), and the F1, F0.5 and F2 scores. Models were trained on a large collection of 50 binary classification radiomic datasets derived from CT and MRI of various organs and representing different clinical outcomes. Evaluation was performed using nested, stratified 5-fold cross-validation with 10 repeats. Nine feature projection methods, including PCA, Kernel PCA, and Non-Negative Matrix Factorization (NMF), were compared to nine selection methods, such as Minimum Redundancy Maximum Relevance (MRMRe), Extremely Randomized Trees (ET), and LASSO, using four classifiers. The results showed that selection methods, particularly ET, MRMRe, Boruta, and LASSO, achieved the highest overall performance. Importantly, performance varied considerably across datasets, and some projection methods, such as NMF, occasionally outperformed all selection methods on individual datasets, indicating their potential utility. However, the average difference between selection methods and projection methods across all datasets was negligible and statistically insignificant, suggesting that both perform similarly based solely on methodological considerations. These findings support the notion that, in a typical radiomics study, selection methods should remain the primary approach but also emphasize the importance of considering projection methods in order to achieve the highest performance.",s41598-025-16070-w,https://www.nature.com/articles/s41598-025-16070-w,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
180,Enhancing cybersecurity in virtual power plants by detecting network based cyber attacks using an unsupervised autoencoder approach,"The increasing adoption of the Internet of Things (IoT) in energy systems has brought significant advancements but also heightened cyber security risks. Virtual Power Plants (VPPs), which aggregate distributed renewable energy resources into a single entity for participation in energy markets, are particularly vulnerable to cyber-attacks due to their reliance on modern information and communication technologies. Cyber-attacks targeting devices, networks, or specific goals can compromise system integrity. Common attack types include Denial of Service (DoS), Man-in-the-Middle (MITM), and False Data Injection Attacks (FDIA).Among these threats, FDIA are especially concerning as they manipulate critical operational data, such as bid prices and energy quantities, to disrupt system reliability, market stability, and financial performance. This study proposes an unsupervised Autoencoder (AE) deep learning approach to detect FDIA in VPP systems. The methodology is validated on a 9-bus and IEEE-39 bus test system modeled in MATLAB Simulink, encompassing renewable energy sources, energy storage systems, and variable loads. Time-series data generated over 1,000 days is used for training, validation, and testing the AE model. The results demonstrate the model’s ability to detect anomalies with high accuracy by analyzing reconstruction errors. By identifying false data, the approach ensures system reliability, protects against financial losses, and maintains energy market stability. This work highlights the importance of advanced machine learning techniques in enhancing cyber security for IoT-based energy systems and ensuring secure VPP operations.",s41598-025-01863-w,https://www.nature.com/articles/s41598-025-01863-w,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
175,Fuzzy controller-driven pattern search optimization for a DC–DC boost converter to enhance photovoltaic MPPT performance,"This article demonstrates maximum power point tracking (MPPT) using a DC-DC boost converter. It introduces an intelligent control technique with fuzzy-based pattern search (PS) optimization for the MPPT controller, enhancing energy conversion efficiency. The fuzzy-PS approach is further refined with PA optimization. A comprehensive performance evaluation compares it with various optimization algorithms. The controller is tested under changes in irradiance and temperature, showing its performance against the Perturb and Observe (P&O) algorithm. The fuzzy controller is optimized to provide the best membership functions (MFs) using PS optimization, particle swarm optimization (PSO), and genetic algorithm (GA), with root mean square error (RMSE) as the objective function. PS optimization outperforms other algorithms. The fuzzy-PS optimization achieves the lowest RMSE of 0.6861 after 100 iterations, while fuzzy-GA and fuzzy-PSO reach RMSEs of 1.257 and 0.9454, respectively. The proposed fuzzy-PS MPPT controller effectively adapts to irradiance and temperature variations, achieving maximum power outputs up to 74.48 kW and Comparative evaluations revealed an average MPPT efficiency of 99.7%, demonstrating superior tracking performance compared to the P&O algorithm.",s41598-025-16255-3,https://www.nature.com/articles/s41598-025-16255-3,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
171,Machine learning for the prediction of blood transfusion risk during or after mitral valve surgery: a multicenter retrospective cohort study,"This study aimed to identify the optimal prediction method and key preoperative variables for red blood cell (RBC) transfusion risk in patients undergoing mitral valve surgery. We conducted a retrospective study involving 1477 patients from eight large tertiary hospitals in China who underwent mitral valve surgery with cardiopulmonary bypass. From thirty collected preoperative variables, the Max-Relevance and Min-Redundancy (mRMR) method was used for feature selection, and various machine learning models were evaluated. Of the 1477 patients, 862 received RBC transfusions. The mRMR method identified ten significant preoperative variables. The LightGBM model demonstrated superior performance, achieving an area under the curve (AUC) of 0.935 in the training set and 0.734 in the validation set, with 74.2% accuracy in a prospective dataset. SHAP analysis revealed the ten most influential variables were hematocrit, RBC count, weight, body mass index, fibrinogen, hemoglobin, height, age, left ventricular dilation, and sex. In conclusion, LightGBM was identified as the optimal model for predicting RBC transfusion needs. The model’s high accuracy can assist clinicians in anticipating transfusions and improving blood management decisions.",s41598-025-16924-3,https://www.nature.com/articles/s41598-025-16924-3,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
170,Dual-self-learning co-evolutionary algorithm for energy-efficient flexible job shop scheduling problem with processing- transportation composite robots,"The processing-transportation composite robots, with their dual functions of processing and transportation, as well as comprehensive robot-machine interactions, have been widely and efficiently applied in the manufacturing industry, leading to a continuous increase in energy consumption. Hence, this work focuses on investigating robot-machine integrated energy-efficient scheduling in flexible job shop environments. To address the new problem, an innovative mixed-integer linear programming model and a novel dual-self-learning co-evolutionary algorithm are proposed, aimed at minimizing the total energy consumption and makespan. In the proposed algorithm, a three-dimensional vector is first used to comprehensively express the solution, and then a greedy decoding strategy is designed to reduce the idle time and energy consumption simultaneously. A hybrid initialization method with adaptive random selection and chaos mapping is developed to ensure the diversity and high quality of the initial solutions. A dual-self-learning mechanism, including a self-learning evolutionary mechanism and a self-learning cooperation mechanism, is designed to select suitable evolutionary operators and enhance interactions between populations, respectively. Finally, multiple sets of experiments are conducted to demonstrate the effectiveness of the proposed mathematical model, improved components and algorithm through numerical, statistical, and differential analyses.",s41598-025-11890-2,https://www.nature.com/articles/s41598-025-11890-2,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
169,Multiscale detection of power quality disturbances and cyber intrusions in smart grids using NSCT and frequency band scalograms,"This paper presents a novel multiscale signal processing framework for power quality disturbance (PQD) and cyber intrusion detection in smart grids, combining Non-Subsampled Contourlet Transform (NSCT), Split Augmented Lagrangian Shrinkage Algorithm (SALSA), and Morphological Component Analysis (MCA). A key innovation lies in an adaptive weighting mechanism within NSCT’s directional sub bands, enabling dynamic energy redistribution and enhanced representation of both low-frequency anomalies (e.g., voltage sags/swells) and high-frequency distortions (e.g., harmonics, transients). SALSA-based sparse optimization achieves an average signal-to-noise ratio (SNR) improvement of 12.8 dB, preserving essential transient structures, while MCA isolates fault-relevant morphological components for better interpretability. Extensive simulations on both synthetic signals and the IEEE 14-bus test system demonstrate detection accuracies of 98.6% for PQDs and 97.2% for cyber intrusions, including False Data Injection (FDI), Denial of Service (DoS), and Command Injection attacks. Each intrusion exhibits unique time-frequency scalogram signatures, which are effectively visualized using high-resolution, denoised 2D/3D spectrograms generated via adaptive Q-Factor Wavelet Transform (AQWT) and Short-Time Fourier Transform (STFT). Compared to baseline methods like STFT-only and DWT-SVM pipelines, the proposed NSCT-SALSA-MCA framework improves detection precision by 14–18%, reduces false positives by 22%, and remains robust under 30 dB noise and 20% data loss. Incorporating AI-driven anomaly detection and resilient state estimation further enables early flagging of compromised measurements, securing applications such as Economic Dispatch and Optimal Power Flow (OPF). The resulting scalograms provide interpretable visual insights, marking a significant advancement in smart grid monitoring with potential for real-time deployment at the edge.",s41598-025-18127-2,https://www.nature.com/articles/s41598-025-18127-2,Scientific Reports,2025-09-05,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
164,A very handy neural interface,"With expanding interest in new brain–computer interface (BCI) technologies for clinical and non-clinical applications, a major challenge is the generalizability of BCI decoding models across diverse populations. In a paper published inNature, Kaifosh, Reardon, and a team from CTRL-labs at Reality Labs report on the development of a surface electromyography (sEMG) wristband capable of decoding hand gestures from wrist muscle activity. They found large across-session and across-user variability in sEMG signals, and focused on building generalizable neural network models trained on data from large numbers of diverse participants. When trained on data from around 1,000 participants or more, these models achieved more than 90% gesture categorization performance when tested on fully naive individuals. Short sessions of personalization training could further boost performance for handwriting decoding, especially for the participants for whom the generic model gave the weakest performance. This paper therefore presents a landmark case study for the development of ‘ready-to-use’ BCI decoders that perform well in the absence of costly single-user training.Original reference:Naturehttps://doi.org/10.1038/s41586-025-09255-w(2025)",s41593-025-02057-3,https://www.nature.com/articles/s41593-025-02057-3,Nature Neuroscience,2025-09-05,,incremental,2025-09-12T17:58:59,2025-09-12T17:58:59
157,Digital twins for the personal touch,"A digital twin, or virtual organ, can help clinicians and patients make better decisions, and can even help in the design of more-efficient clinical trials. Noble, D.Nature188, 495–497 (1960).ArticlePubMedCASGoogle ScholarPassini, E. et al.Front. Physiol.8, 668 (2017).ArticlePubMedPubMed CentralGoogle ScholarWu, C. et al.npj Digit. Med.8, 195 (2025).ArticlePubMedPubMed CentralGoogle ScholarWalsh, J. R., Roumpanis, S., Bertolini, D. & Delmar, P.Alzheimers Dementia18, e065386 (2022).ArticleGoogle ScholarDownload references Authors and AffiliationsFreelance writer, Toronto, Ontario, CanadaPaul WebsterAuthorsPaul WebsterView author publicationsSearch author on:PubMedGoogle Scholar Reprints and permissions Cite this articleWebster, P. Digital twins for the personal touch.Nat Med(2025). https://doi.org/10.1038/s41591-025-03938-7Download citationPublished:05 September 2025DOI:https://doi.org/10.1038/s41591-025-03938-7Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s41591-025-03938-7,https://www.nature.com/articles/s41591-025-03938-7,Nature Medicine,2025-09-05,,incremental,2025-09-12T17:54:50,2025-09-12T17:54:50
159,Digital cognitive twins in mental health,"Digital cognitive twins could transform cognitive training into a personalized, clinically grounded and ethically governed modality for preventive use. Yaffe, K. et al.JAMA Intern. Med.184, 54–62 (2024).ArticlePubMedGoogle ScholarStallard, P. J. E., Ukraintseva, S. V. & Doraiswamy, P. M.JAMA333, 1579–1580 (2025).ArticlePubMedGoogle ScholarHallion, L. S., Hsu, K. J. & Schleider, J. L.Nat. Ment. Health2, 17–24 (2024).ArticleGoogle ScholarBodner, K. A., Goldberg, T. E., Devanand, D. P. & Doraiswamy, P. M.Front. Psychiatry11, 557571 (2020).ArticlePubMedPubMed CentralGoogle ScholarDevanand, D. P. et al.NEJM Evid.https://doi.org/10.1056/EVIDoa2200121(2022).ArticlePubMedPubMed CentralGoogle ScholarNwosu, A., Boardman, S., Husain, M. M. & Doraiswamy, P. M.Front. Psychiatry13, 900615 (2022).ArticlePubMedPubMed CentralGoogle ScholarDoraiswamy, P. M., Narayan, V. A. & Manji, H. K.npj Digit. Med.1, 1 (2018).ArticlePubMedPubMed CentralGoogle ScholarChan, A. T. C., Ip, R. T. F., Tran, J. Y. S., Tran, J. Y. C. & Tsoi, K. K. F.npj Digit. Med.7, 1 (2024).ArticlePubMedPubMed CentralGoogle ScholarRichter, T. et al.npj Digit. Med.8, 65 (2025).ArticlePubMedPubMed CentralGoogle ScholarOoka, T.Japan Med. Assoc. J.8, 1–10 (2025).Google ScholarNahum-Shani, I. et al.Ann. Behav. Med.52, 446–462 (2018).ArticlePubMedGoogle ScholarIbrahim, M. et al.Comput. Biol. Med.189, 109834 (2025).ArticlePubMedGoogle ScholarShade, M., Yan, C., Jones, V. K. & Boron, J.JMIR Form. Res.9, e64763 (2025).ArticlePubMedPubMed CentralGoogle ScholarHuang, P. H., Kim, K. H. & Schermer, M.J. Med. Internet Res.24, e33081 (2022).ArticlePubMedPubMed CentralGoogle ScholarLi, X. et al.Genome Med.17, 11 (2025).ArticlePubMedPubMed CentralGoogle ScholarDownload references P.M.D. and D.P.D. are supported by US National Institute on Aging grant 2R01AG052440. Authors and AffiliationsNeurocognitive Disorders Program, Department of Psychiatry, Duke University School of Medicine and Duke Institute for Brain Sciences, Durham, NC, USAP. Murali DoraiswamyCentro de Investigación Nebrija en Cognición (CINC), Nebrija University, Madrid, SpainJon Andoni DuñabeitiaCogniFit, San Francisco, CA, USACarlos RodriguezDivision of Geriatric Psychiatry, New York State Psychiatric Institute and Department of Psychiatry, Columbia University Irving Medical Center, New York, NY, USADavangere P. DevanandAuthorsP. Murali DoraiswamyView author publicationsSearch author on:PubMedGoogle ScholarJon Andoni DuñabeitiaView author publicationsSearch author on:PubMedGoogle ScholarCarlos RodriguezView author publicationsSearch author on:PubMedGoogle ScholarDavangere P. DevanandView author publicationsSearch author on:PubMedGoogle ScholarCorresponding authorCorrespondence toJon Andoni Duñabeitia. Competing interestsP.M.D. and D.P.D. are supported by US National Institute on Aging grant 2R01AG052440, for which CogniFit provides the training platform, but have no other financial relationships with CogniFit. P.M.D. has received research grants, advisory fees and/or stock from several companies in this field for other projects, and serves on the boards of Apollo Hospitals Enterprise Limited (AHEL) and the Live Love Laugh Foundation. D.P.D. is a scientific consultant to Acadia, Eisai and GSK. J.A.D. serves as a scientific advisor for CogniFit. Peer review informationNature Mental Healththanks Tadao Ooka for their contribution to the peer review of this work. Reprints and permissions Cite this articleDoraiswamy, P.M., Duñabeitia, J.A., Rodriguez, C.et al.Digital cognitive twins in mental health.Nat. Mental Health(2025). https://doi.org/10.1038/s44220-025-00482-8Download citationPublished:04 September 2025DOI:https://doi.org/10.1038/s44220-025-00482-8Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s44220-025-00482-8,https://www.nature.com/articles/s44220-025-00482-8,Nature Mental Health,2025-09-04,,incremental,2025-09-12T17:55:29,2025-09-12T17:55:29
145,5thanniversary focus: author Peter Fretwell on penguins and climate change,"Peter Fretwell is a senior scientist in the Mapping and Geographic Information Centre, at the British Antarctic Survey. Peter has pioneered the use of satellite imagery to study polar wildlife such as penguins, walrus, whales, and seabirds; and has authored books on penguins and Antarctic environments.Peter Fretwell.Credit: British Antarctic Survey I have always loved the curiosity-based science and the feeling you get when finding new things and publishing new research. It is that discovery aspect that really drives me and keeps me interested. Being the first person to see something or work something out really inspires my research.But it took me a while to find my path. I sort of fell into science rather late in my career. It wasn’t until my mid-thirties that I published my first paper and not until I was 49 before I got my PhD. I started working at British Antarctic Survey twenty-four years ago, my first post was Temporary Assistant Map Curator, but it was a foot in the door and got me into a great science organisation with inspiring people and a long history of discovery. Since then, I have worked my way up through a number of posts until now I am a senior scientist with my own internal research group. But it is still that sense of wonder and excitement that you get from a new discovery that inspires me. I am a remote sensing scientist by trade, so for me the most exciting thing in the pipeline are the new Earth observation satellites that are being launched. Over the last decade or two, these satellite platforms have been getting more powerful with better resolution, faster return rates, and more capable sensors.There are plans to launch 10 cm resolution optical commercial satellites and sub metre thermal satellites and we have recently had a number of high-resolution Synthetic Aperture Radar (SAR) platforms launched. These open up huge new research areas. Mix those new satellites with the increasing ability of AI to automate analysis and our ability to incorporate “big data” and the Earth observation field will be an obvious growth area in coming years. The Polar Regions, which I work on, are changing at an unprecedented rate, so the need for remote sensing is urgent. In many cases, the environment and ecology are changing without us even noticing it. Environmental remote sensing has traditionally looked at things on a coarse spatial scale – habitat mapping, vegetation and land-use are classic examples. That is mainly because in the past, the spatial resolution of the satellite sensors has been fairly coarse. But with a move to higher spatial resolution, we can actually monitor individual animals rather than estimate them by mapping their habitat. With the number of new satellite-platforms, the huge amount of data gives massive scope for a revolution in Earth Observation. To do that effectively we need automation and that means AI and Machine Learning. That automation is one of my group’s focus areas. The AI landscape is fast moving and keeping up with it means collaborating with experts in the field. Those interdisciplinary collaborations between AI experts, remote sensors and ecologists will be key to taking the science forwards. It’s the twin challenge of incorporating massive technological improvements, but with an ever-increasing need. The three challenges of Climate Change, Habitat Destruction and Pollution are pushing more species towards extinction, and we know that with climate change it is going to get a lot worse before it gets better. We need to be able to detect, monitor and communicate the effects that the changing planet is having on our ecosystems and species to inform the public and policy makers to make the changes needed.On the other hand, there are the funding and political challenges that we have seen recently that make the future suddenly look so unsure. With cuts to environmental science budgets in many nations and political upheavals, keeping our eye the environmental needs and opportunities, rather than fire-fighting those problems will be key to the next five years. Our paper1on the catastrophic breeding failure of emperor penguins had massive impact – from the metrics I have read, of all 370,000 papers published in the last two years, that paper was ranked 36thhighest impact. That is all research globally in all academic journals in the 99.9% of impact. It has certainly opened doors and got lots of people talking about climate change and penguins. For me, the paper has helped with several funding bids and engagements, and I have published another paper in the journal earlier this year. I’m employed by the British Antarctic Survey, that means that most of my research is Polar. It’s not always Antarctica; I often work on species in the Arctic and have published papers on walrus and beluga whales and done fieldwork in Svalbard, although it’s fair to say that most of my research is in the Southern Ocean and Antarctic region. Being in Cambridge is also a great benefit. Our institute is a government research institute, but having Cambridge University on our doorstep makes a difference. We have had many collaborative projects especially with the Cambridge Maths and Image Analysis Departments, who have a depth of knowledge and experience in AI. On a larger scale being in the UK helps too, the research scene is always vibrant and collaborative and there is a genuine buzz about environmental science. Yes, there are certainly things that we can do to help bridge the inclusion gaps. Over the last couple of decades, we have seen great leaps forward in gender inclusion in our field in the UK, but we still need to address other types of social inclusion that are obvious. Environmental science is still very white, middle class, and does not always reflect the general population. From what I can see, it seems to be a cultural thing rather than a specific recruitment bias- we just are not attracting a diverse range of recruits from other social and cultural backgrounds. Maybe other cultures do not see environmental science in the same way or are driven by other motives than what science and the environment can give them. So, balancing the inclusion will be problematic and take time. There have been several good initiatives to help, and we must keep trying to open those doors and make our science attractive to the whole range of groups and cultures. One thing I have learned is that you need to have a thick skin to be a scientist. Publishing papers, writing research grants, planning challenging fieldwork; all of them can lead to knock backs. Sometimes reviews of your papers can seem quite personal and be hard to take. I’ve had reviews that say that a particular paper should never be published. And big grants, that you’d put months’ worth of effort that were cancelled at the last minute, when you thought that you had them in the bag. But what experience tells you is that there is always another paper, always another grant opportunity or project. It’s hard not to get emotionally involved with your research, but sometimes you have to just take the hit and move on. That is really tricky when you are an early career scientist, when each paper means more.One particular challenge I had was when I was doing my Master’s degree. I have a field site in Scotland on a cattle farm where I was supposed to collect all my field data. I’d only been there for two days when Mad Cow disease hit Scotland. In a panicked phone call my supervisor instructed me to get out immediately or I would be quarantined. When I got back to the university I was stuck several months into my year’s course with no data and a cancelled project. Some people advised me to wait it out, but the quarantine lasted for a year. Luckily, I was able to change my research from a field project to a modelling study, based on existing data. On the way, I learn new analytical skills like GIS which stood me in good stead for my future career. Without that change I would never have ended up where I am now. This interview was conducted by the editors of Communications Earth & Environment. Fretwell, P. T., Boutet, A. & Ratcliffe, N. Record low 2022 Antarctic sea ice led to catastrophic breeding failure of emperor penguins.Commun. Earth Environ.4, 273 (2023).ArticleGoogle ScholarDownload references Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visithttp://creativecommons.org/licenses/by/4.0/.Reprints and permissions Cite this article5thanniversary focus: author Peter Fretwell on penguins and climate change.Commun Earth Environ6, 740 (2025). https://doi.org/10.1038/s43247-025-02752-wDownload citationPublished:04 September 2025DOI:https://doi.org/10.1038/s43247-025-02752-wShare this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s43247-025-02752-w,https://www.nature.com/articles/s43247-025-02752-w,Communications Earth & Environment,2025-09-04,,incremental,2025-09-12T17:12:25,2025-09-12T17:12:25
144,Fifth anniversary: Debate is the essence of community,"Lockdowns loomed large whenCommunications Earth & Environmentlaunched 5 years ago. Since restrictions lifted, we have seen a push-back on science as well as an AI revolution. In response, the global community of Earth and environmental researchers must stand together, while remaining open-minded. The world has become more polarised, especially post-pandemic. Science is valued by large parts of societies globally, but there are sizable and sometimes influential groups that no longer accept the premise that research is a path to progress. At the same time, artificial intelligence systems and in particular Large Language Models are profoundly changing the knowledge landscape. In such a less trustful and fast-evolving world, robust debate, openness and transparency are – more than ever – the hallmarks of defensible science. Right from thelaunchofCommunications Earth & Environmentin 2020, it has been the mission of the journal to give the community of Earth, planetary and environmental scientists a forum for transparent research and discussion, open to public scrutiny. Ultimately, our aim is twofold: to strengthen community among researchers and to enable open dialogue with the public. To mark our fifth anniversary, we are assembling aCollection of Opinion piecesthat highlight some of the amazing articles that we have published, and reflect on the journal’s journey, as well as on our aims as editors. We will be adding to the Collection throughout the year, showcasing and celebrating authors’, reviewers’ and editors’ points of view. With our content, all of which is openly accessible, we hope to reach beyond the science community and inform the thinking of the public at large. Public trust in science matters to our mission. Yet it can not be taken for granted. In a survey of almost 72,000 respondents in 68 countries, scientists were found to be trusted overall1, countering a popular narrative to the contrary. Minorities that have little trust exist, however, and can influence public opinion and policy makers. Among those surveyed, people with populist beliefs on science-related topics, or with a preference for social hierarchy and inequality, were less likely to trust scientists. Perhaps less expectedly, political leanings did not show consistent correlations with trust in science across countries; also, two different indicators of political inclination – left-right and liberal-conservative – delivered different outcomes. It is not easy to draw conclusions on how to support trust in the broader public from these findings. Two insights from the study stand out: a recommendation that the research enterprise as a whole needs to address topics that the public find important, such as improving public health and solving energy problems. And a call for scientists to be open to true two-way dialogue, to invite feedback and public participation. In a more challenging societal environment, it may seem more comfortable to close down communication with those who don’t trust us and henceforth talk to the like-minded. That would exacerbate polarisation. Instead, it remains essential to seek out and carefully examine alternative viewpoints. As a journal,Communications Earth & Environmentcontinues to invite lively debate into our pages and encourage public participation in the scientific discourse. One hotly debated topic is the use of artificial intelligence in science and scientific publishing. We have received queries from authors asking whether a reviewer report was written by a Large Language Model, just as we have had queries from reviewers who thought an article they were reviewing was produced by generative AI. These questions show how the rise of artificial intelligence has undermined trust among scientists: it is no longer taken for granted that researchers do their best to understand the world around them. In response to such questions, we insist, of course, that oureditorial policies on Artificial Intelligenceare followed. And we continually review these policies to keep them updated as field evolves. Most importantly, it is crucial that confidentiality of unpublished research is preserved. Despite its drawbacks, it is important to remember that artificial intelligence is a valuable tool, just as it can be abused. AI-based systems can make data analysis and modelling much more efficient. And Large Language Models can empower researchers around the world to write persuasively in English. Because it is impossible to discern with certainty whether an AI-based system was used solely for simple language refinement or for core content generation, we recommend that authors and reviewers leave this question aside and instead focus on the content. Assessments are best when they are based on the scientific merits, originality and relevance of the manuscript or peer review report at hand, and not on perceptions of how the text may have been put together. For the future, we call on the community of Earth, planetary and environmental scientists to experiment and debate with an open mind how this and other evolving technologies can best advance discovery, while maintaining trust and transparency. As editors atCommunications Earth & Environment– whether as internal editors or Editorial Board Members – we seek to publish novel and thought-provoking articles that influence the thinking of the communities we serve and the public at large. We are enormously grateful to all our authors, reviewers and readers over the past five years that they have come together and made the journal such a vibrant forum for the exchange of ideas and opinions. We look forward to continuing this shared commitment to open, constructive debate in the years ahead.Credit: Westend61 Cologna, V. et al. Trust in scientists and their role in society across 68 countries.Nat. Hum. Behav.9, 713–730 (2025).ArticleGoogle ScholarDownload references Publisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open AccessThis article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visithttp://creativecommons.org/licenses/by-nc-nd/4.0/.Reprints and permissions Cite this articleFifth anniversary: Debate is the essence of community.Commun Earth Environ6, 741 (2025). https://doi.org/10.1038/s43247-025-02723-1Download citationPublished:04 September 2025DOI:https://doi.org/10.1038/s43247-025-02723-1Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboardProvided by the Springer Nature SharedIt content-sharing initiative",s43247-025-02723-1,https://www.nature.com/articles/s43247-025-02723-1,Communications Earth & Environment,2025-09-04,,incremental,2025-09-12T17:12:25,2025-09-12T17:12:25
118,Applying genomic AI to combat antibiotic resistance in low-income countries,"Advances in whole-genome sequencing and machine learning have transformed the landscape of antibiotic resistance (ABR) prediction, offering the potential to identify effective therapies hours to days faster than conventional culture-based assays1. By encoding genomic features, such as ABR gene variants and single-nucleotide polymorphisms, into classifiers such as random-forest algorithms and deep neural networks, researchers have achieved remarkable accuracy for several bacterial pathogens2,3. These ‘genomic artificial intelligence’ (genomic AI) approaches promise to empower clinicians at the point of care, potentially saving lives in low-income countries (LICs), where delays in appropriate therapy can be lethal. Translating these models from research to routine use, however, demands rigorous external validation4. A tool trained exclusively on European or Asian isolates may perform poorly when applied to African or Latin American isolates, as minor genomic variations can obscure critical ABR determinants4. To guard against ‘shortcut’ learning, in which models rely on spurious correlations rather than true causal features, performance must be evaluated on fully independent cohorts from the intended clinical environment4.In practice, local validation can involve held-out retrospective or prospective isolated collections, followed by finetuning to recalibrate the model to regional genomic and phenotypic patterns4. Routine retraining on fresh data — whether monthly, quarterly or after a threshold of new cases is reached — helps models adapt to the evolving microbial landscape, a phenomenon known as covariate drift. Studies in other healthcare domains have shown that periodically retrained models retain discriminatory power, while static ones suffer significant declines in AUROC (area under the receiver operating characteristic curve, a measure of predictive power) and calibration5. In LICs, where pathogen diversity is high and surveillance resources are limited, dynamic retraining is not a luxury but a necessity: without it, ‘train once, use forever’ systems risk making dangerously inaccurate recommendations.",s42256-025-01108-5,https://www.nature.com/articles/s42256-025-01108-5,Nature Machine Intelligence,2025-09-04,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
195,Detecting suicide risk in bipolar disorder patients from lymphoblastoid cell lines genetic signatures,"This research aimed to develop a machine learning algorithm to predict suicide risk in bipolar disorder (BD) patients using RNA sequencing analysis of lymphoblastoid cell lines (LCLs). By identifying differentially expressed genes (DEGs) between high and low risk patients and their enrichment in relevant pathways, we gained insights into the molecular mechanisms underlying suicide risk. LCL gene expression analysis revealed pathway enrichment related to primary immunodeficiency, ion channels, and cardiovascular defects. Notably, genes such asLCK, KCNN2, andGRIA1emerged as pivotal, suggesting their potential roles as biomarkers. Machine learning algorithms trained on a subset of the patients and tested on others demonstrated high accuracy in distinguishing low and high risk of suicide in BD patients. Additionally, the study explored the genetic overlap between suicide-related genes and several psychiatric disorders. Our study enhances the understanding of the complex interplay between genetics and suicidal behaviour, providing a foundation for prevention strategies.",s41398-025-03573-3,https://www.nature.com/articles/s41398-025-03573-3,Translational Psychiatry,2025-09-03,,incremental,2025-09-12T18:18:36,2025-09-12T18:18:36
192,Pancancer outcome prediction via a unified weakly supervised deep learning model,"Accurate prognosis prediction is essential for guiding cancer treatment and improving patient outcomes. While recent studies have demonstrated the potential of histopathological images in survival analysis, existing models are typically developed in a cancer-specific manner, lack extensive external validation, and often rely on molecular data that are not routinely available in clinical practice. To address these limitations, we present PROGPATH, a unified model capable of integrating histopathological image features with routinely collected clinical variables to achieve pancancer prognosis prediction. PROGPATH employs a weakly supervised deep learning architecture built upon the foundation model for image encoding. Morphological features are aggregated through an attention-guided multiple instance learning module and fused with clinical information via a cross-attention transformer. A router-based classification strategy further refines the prediction performance. PROGPATH was trained on 7999 whole-slide images (WSIs) from 6,670 patients across 15 cancer types, and extensively validated on 17 external cohorts with a total of 7374 WSIs from 4441 patients, covering 12 cancer types from 8 consortia and institutions across three continents. PROGPATH achieved consistently superior performance compared with state-of-the-art multimodal prognosis prediction models. It demonstrated strong generalizability across cancer types and robustness in stratified subgroups, including early- and advanced-stage patients, treatment cohorts (radiotherapy and pharmaceutical therapy), and biomarker-defined subsets. We further provide model interpretability by identifying pathological patterns critical to PROGPATH’s risk predictions, such as the degree of cell differentiation and extent of necrosis. Together, these results highlight the potential of PROGPATH to support pancancer outcome prediction and inform personalized cancer management strategies.",s41392-025-02374-w,https://www.nature.com/articles/s41392-025-02374-w,Signal Transduction and Targeted Therapy,2025-09-03,,incremental,2025-09-12T18:17:18,2025-09-12T18:17:18
168,A lightweight hybrid model for scalable and robust plant leaf disease classification,"Plant leaf diseases significantly impact crop yield and quality, causing substantial economic loss and risking food security. Despite significant progress in the field of automated plant disease diagnosis, there are still several challenges that need to be addressed. Accurate classification of plant leaf diseases at an early stage is crucial for diagnosis and effective treatment of these plant diseases. As the agricultural industry faces growing challenges from plant diseases, quickly identifying these diseases in a field environment while considering the computational resource limitations is more important than ever. To overcome these challenges, this study proposed a lightweight and compact convolutional neural network model, HPDC-Net (Hybrid Plant Disease Classification Network). The network used a block architecture with three blocks termed as Depth-wise Separable Convolution Block (DSCB), Dual-Path Adaptive Pooling Block (DAPB), and Channel-Wise Attention Refinement Block (CARB). The model extracts a robust but limited number of features due to the use of depth-wise separable convolutions in DSCB, making it accurate but lightweight. The proposed model has been trained to classify potato and tomato leaf diseases on three datasets. The model achieves a high accuracy score > 99% on all three datasets while keeping GFLOPs limited to 0.06 and the number of parameters to 0.52 M (for 10 classes) and 0.17 M (for 03 classes), yielding 19.82 FPS on CPU and 408.25 FPS on GPU in our setup. The code for implementation of proposed model is available on GitHub:https://github.com/ZahidFarooqKhan/HPDC-Net.",s41598-025-08788-4,https://www.nature.com/articles/s41598-025-08788-4,Scientific Reports,2025-09-03,,incremental,2025-09-12T18:16:21,2025-09-12T18:16:21
165,Innovation with rigor in personalized medicine: back to the basics,"The field of neuropsychopharmacology has entered an era of data science poised to accelerate personalized medicine. Studies harness novel computational tools to predict, and assign tailored treatments based on, person-level characteristics. However, data science methods are increasingly complex, obscuring translational potential, and attention to basic standards of rigor has been inconsistent. Psychiatric data science models do not reflect progress unless they are accurate (they aretrue), they outperform others (they arebetter), and they are interpretable and scalable (they areusable).Confidence in thetruthof psychiatric data science models requires them to meet requirements of validity, reliability, and replication. Prior research has not consistently met this standard, with many psychiatric prediction models found to be at “high risk of bias” [1]. Even investigators with a good understanding of techniques for ensuring accuracy of measurementmethodsmay be unfamiliar with techniques for testing accuracy of themodel, or of risks for bias or overfitting. Fortunately, robust techniques are available, e.g., comparing the augmented to a null model [2] and cross-validating results [2,3] is one approach to quantify and test reliability of model performance. Complementary approaches fend against overfitting and increase validity, such as early stopping (i.e., terminating model iteration as performance degrades in a validation set; [4]). An important direction for psychiatric data science is dissemination and standardization of tools to test model accuracy.",s41386-025-02228-7,https://www.nature.com/articles/s41386-025-02228-7,Neuropsychopharmacology,2025-09-03,,incremental,2025-09-12T18:05:06,2025-09-12T18:05:06
133,Supervised learning in DNA neural networks,"Learning enables biological organisms to begin life simple yet develop immensely diverse and complex behaviours. Understanding learning principles in engineered molecular systems could enable us to endow non-living physical systems with similar capabilities. Inspired by how the brain processes information, the principles of neural computation have been developed over the past 80 years1, forming the foundation of modern machine learning. More than four decades ago, connections between neural computation and physical systems were established2. More recently, synthetic molecular systems, including nucleic acid and protein circuits, have been investigated for their abilities to implement neural computation3,4,5,6,7. However, in these systems, learning of molecular parameters such as concentrations and reaction rates was performed in silico to generate desired input–output functions. Here we show that DNA molecules can be programmed to autonomously carry out supervised learning in vitro, with the system learning to perform pattern classification from molecular examples of inputs and desired responses. We demonstrate a DNA neural network trained to classify three different sets of 100-bit patterns, integrating training data directly into memories of molecular concentrations and using these memories to process subsequent test data. Our work suggests that molecular circuits can learn tasks more complex than simple adaptive behaviours. This opens the door to molecular machines capable of embedded learning and decision-making in a wide range of physical systems, from biomedicine to soft materials.",s41586-025-09479-w,https://www.nature.com/articles/s41586-025-09479-w,Nature,2025-09-03,,incremental,2025-09-12T16:52:32,2025-09-12T16:52:32
132,Adaptive and context-aware volumetric printing,"We introduce Generative, Adaptive, Context-Aware 3D Printing (GRACE), a new approach combining 3D imaging, computer vision and parametric modelling to create tailored, context-aware geometries using volumetric additive manufacturing. GRACE rapidly and automatically generates complex structures capable of conforming directly around features ranging from cellular to macroscopic scales with minimal user intervention. Here we demonstrate its versatility in applications ranging from synthetic objects to biofabrication, including adaptive vascular-like geometries around cell-laden bioinks, resulting in improved functionality. GRACE also enables precise alignment of sequential prints, as well as the detection and overprinting of opaque surfaces through shadow correction. Compatible with various printing modalities1,2,3,4, GRACE transcends traditional additive manufacturing limitations in automating overprinting and adapting the printed designs to the content of the printable material. This opens new possibilities in tissue engineering and regenerative medicine.",s41586-025-09436-7,https://www.nature.com/articles/s41586-025-09436-7,Nature,2025-09-03,,incremental,2025-09-12T16:52:32,2025-09-12T16:52:32
131,Analog optical computer for AI inference and combinatorial optimization,"Artificial intelligence (AI) and combinatorial optimization drive applications across science and industry, but their increasing energy demands challenge the sustainability of digital computing. Most unconventional computing systems1,2,3,4,5,6,7target either AI or optimization workloads and rely on frequent, energy-intensive digital conversions, limiting efficiency. These systems also face application-hardware mismatches, whether handling memory-bottlenecked neural models, mapping real-world optimization problems or contending with inherent analog noise. Here we introduce an analog optical computer (AOC) that combines analog electronics and three-dimensional optics to accelerate AI inference and combinatorial optimization in a single platform. This dual-domain capability is enabled by a rapid fixed-point search, which avoids digital conversions and enhances noise robustness. With this fixed-point abstraction, the AOC implements emerging compute-bound neural models with recursive reasoning potential and realizes an advanced gradient-descent approach for expressive optimization. We demonstrate the benefits of co-designing the hardware and abstraction, echoing the co-evolution of digital accelerators and deep learning models, through four case studies: image classification, nonlinear regression, medical image reconstruction and financial transaction settlement. Built with scalable, consumer-grade technologies, the AOC paves a promising path for faster and sustainable computing. Its native support for iterative, compute-intensive models offers a scalable analog platform for fostering future innovation in AI and optimization.",s41586-025-09430-z,https://www.nature.com/articles/s41586-025-09430-z,Nature,2025-09-03,,incremental,2025-09-12T16:52:32,2025-09-12T16:52:32
152,Phosphorus constrains global photosynthesis more than nitrogen does,"Global vegetation growth is thought to be limited by nitrogen (N) more than by other nutrients. Here we document a stronger phosphorus (P) limitation on global photosynthesis compared with N over the last four decades. On the basis of more than 80,000 field observations of foliar nutrients and a machine learning method, we generated a long-term global dataset of foliar N and P concentrations for the period 1980–2017. We show a larger declining rate of foliar P concentration (−0.80 ± 0.008% yr−1) than of N concentration (−0.31 ± 0.002% yr−1). This decline has led to an increase in terrestrial areas limited by foliar P and a widespread constraint on vegetation photosynthesis, more than 1.5 times stronger than the constraint by foliar N. The increasing trend in global photosynthesis over the past 4 decades has been reduced by approximately 17.2% and 6.7% as a result of the decline in foliar P and N, respectively. This stronger P limitation on global photosynthesis implies a weakening of terrestrial carbon sinks due to an emerging P constraint and calls for stricter strategies for reducing anthropogenic emissions to mitigate climatic warming.",s41559-025-02842-0,https://www.nature.com/articles/s41559-025-02842-0,Nature Ecology & Evolution,2025-09-02,,incremental,2025-09-12T17:47:31,2025-09-12T17:47:31
151,Bridging AI literacy and UTAUT constructs: structural equation modeling of AI adoption among Chinese university students,"In the rapidly evolving landscape of artificial intelligence (AI), understanding the factors that influence individuals’ intentions to adopt AI technologies is crucial, particularly within educational contexts. This study addresses a critical gap in the literature by examining how AI literacy interacts with the constructs of the Unified Theory of Acceptance and Use of Technology (UTAUT)—Performance Expectancy, Effort Expectancy, Social Influence, and Facilitating Conditions—to shape university students’ behavioral intentions to adopt AI technologies. Data from 359 Chinese university students were analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM). The findings reveal that AI Literacy is a significant predictor of Behavioral Intention to adopt AI, with Social Influence, Performance Expectancy, and Effort Expectancy serving as important mediators. Notably, Facilitating Conditions did not have a significant effect on Behavioral Intention in this context. The results underscore the importance of enhancing AI Literacy among university students to foster positive adoption intentions, particularly through social and expectancy-related factors, providing practical implications for educators and policymakers aiming to promote AI integration in higher education.",s41599-025-05775-y,https://www.nature.com/articles/s41599-025-05775-y,Humanities and Social Sciences Communications,2025-09-02,,incremental,2025-09-12T17:23:08,2025-09-12T17:23:08
148,Emergent Wigner phases in moiré superlattice from deep learning,"Moiré superlattice designed in stacked van der Waals material provides a dynamic platform for hosting exotic and emergent condensed matter phenomena. However, the relevance of strong correlation effects and the large size of moiré unit cells pose significant challenges for traditional computational techniques. To overcome these challenges, we develop an unsupervised deep learning approach to uncover electronic phases emerging from moiré systems based on variational optimization of neural network many-body wavefunction. Our approach identifies diverse quantum states, including emergent phases such as generalized Wigner crystals, Wigner molecular crystals, and Wigner covalent crystals. These discoveries provide insights into recent experimental studies and suggest more phases for future exploration. They also highlight the crucial role of spin polarization in determining Wigner phases. More importantly, our proposed deep learning approach is proven general and efficient, offering a powerful framework for studying moiré physics.",s42005-025-02282-z,https://www.nature.com/articles/s42005-025-02282-z,Communications Physics,2025-09-02,,incremental,2025-09-12T17:15:22,2025-09-12T17:15:22
142,Lipidomic profiling of human bile distinguishes cholangiocarcinoma from benign bile duct diseases with high specificity and sensitivity: a prospective descriptive study,"BackgroundCholangiocarcinoma (CCA) is a rare and highly aggressive malignancy originating in the bile ducts. Owing to limitations involving pathological sampling, the clinical differentiation of CCA from benign biliary diseases remains challenging. This study aimed to evaluate the differences between the bile lipidomes of CCA patients and those of patients with benign disease to develop a bile lipid classifier that can help to differentiate CCA from benign conditions.MethodsBile samples were collected by endoscopic retrograde cholangiography (ERCP) from patients with CCA or benign disease. The participants were divided into three cohorts: the first two cohorts underwent untargeted lipidomic analysis, whereas the third cohort was subjected to targeted lipid quantification. Untargeted lipidomic analysis was performed via ultrahigh-performance liquid chromatography coupled with ion mobility quadrupole time-of-flight mass spectrometry (UHPLC/IM-QTOF-MS). Targeted lipid quantification was conducted via UHPLC‒MS/MS in multiple reaction monitoring (MRM) mode. Lipid features were screened to construct a bile lipid classifier using the machine learning algorithm, least absolute shrinkage and selection operator (LASSO) regression, followed by cross-validation in two cohorts. The selected lipid features were further validated by targeted quantification in the third cohort. The functions of the significantly differentially abundant lipids in proliferation were validated in CCA cell lines.ResultsIn total, 241 bile samples were collected and divided into three cohorts for independent lipidomic analysis: Cohort 1 included 32 CCA samples and 68 benign controls; Cohort 2 included 30 CCA samples and 30 benign controls; and Cohort 3 included 32 CCA samples and 49 benign controls. There were significant differences in the lipid profiles of the bile samples obtained from patients with CCA and individuals with benign disease, with multiple lipid classes, particularly lysophosphatidylcholine (LPC), significantly downregulated in the CCA group. Multimodule correlation networks constructed via weighted lipid coexpression network analysis (WLCNA) revealed significant associations between lipid modules and clinical traits. A machine learning-based bile lipid classifier, termed BileLipid, was developed for CCA diagnosis; this classifier incorporates six lipid features. This classifier achieved areas under the receiver operating characteristic curve (AUCs) of 0.943, 0.956, and 0.828 in Cohorts 1, 2, and 3, respectively. Additionally, the significantly downregulated lipid LPC in CCA bile was found to significantly inhibit the proliferation of CCA cell lines, suggesting its potential role as a protective factor in CCA.ConclusionsThis study not only identified lipidomic alterations in CCA using bile samples but also established and validated a sex-related bile lipid classifier with high specificity and sensitivity for distinguishing between CCA and benign bile duct diseases. Our findings highlight the potential of bile lipid biomarkers for improving the differential diagnosis and risk assessment of CCA and preventing potential overintervention in patients with benign biliary disease.",s41416-025-03144-9,https://www.nature.com/articles/s41416-025-03144-9,British Journal of Cancer,2025-09-02,,incremental,2025-09-12T17:03:18,2025-09-12T17:03:18
194,"Dissecting the heterogeneity of autism spectrum disorder with sensory behavior, brain, and epigenetic factors","Autism spectrum disorder (ASD), a disorder with heterogeneous etiology, is characterized by abnormal behavioral responses to sensory inputs. However, there is still limited understanding of how brain and epigenetic factors, along with behavioral abnormality, contribute to ASD. After completing Adolescent-Adult Sensory Profile, a self-report questinnaire, 34 individuals with ASD and 72 controls underwent neuroimaging scans to measure brain structural (cortical and subcortical volume) and functional (thalamo-cortical resting-state functional connectivity) characteristics. For epigenetic measures, we computed DNA methylation values of the oxytocin receptor and arginine vasopressin receptor (AVPR) genes from the participants’ saliva. When sensory-related behavior was the default baseline, a machine learning algorithm demonstrated that theneuroimaging-epigenetic modeloutperformed theneuroimaging modelor theepigenetic model. Thalamo-cortical hyperconnectivity and AVPR 1A epigenetic modification were found to be significant contributing factors in these models. By integrating neuroimaging and epigenetic biomarkers with behaviors, a more precise diagnosis of ASD can be achieved.",s41398-025-03566-2,https://www.nature.com/articles/s41398-025-03566-2,Translational Psychiatry,2025-09-01,,incremental,2025-09-12T18:18:36,2025-09-12T18:18:36
166,"Pulmonary T2* quantification of fetuses with congenital diaphragmatic hernia: a retrospective, case-controlled, MRI pilot study","BackgroundAdvanced MRI techniques, motion-correction and T2*-relaxometry, may provide information regarding functional properties of pulmonary tissue. We assessed whether lung volumes and pulmonary T2* values in fetuses with congenital diaphragmatic hernia (CDH) were lower than controls and differed between survivors and non-survivors.MethodsWomen with uncomplicated pregnancies (controls) and those with a CDH had a fetal MRI on a 1.5 T imaging system encompassing T2 single shot fast spin echo sequences and gradient echo single shot echo planar sequences providing T2* data. Motion-correction was performed using slice-to-volume reconstruction, T2* maps were generated using in-house pipelines. Lungs were segmented separately using a pre-trained 3D-deep-learning pipeline.ResultsDatasets from 33 controls and 12 CDH fetuses were analysed. The mean ± SD gestation at scan was 28.3 ± 4.3 for controls and 27.6 ± 4.9 weeks for CDH cases.CDH lung volumes were lower than controls in both non-survivors and survivors for both lungs combined (5.76 ± 3.59 [cc], mean difference = 15.97, 95% CI: −24.51–−12.9,p< 0.001 and 5.73 ± 2.96 [cc], mean difference = 16, 95% CI: 1.91–11.53,p= 0.008) and for the ipsilateral lung (1.93 ± 2.09 [cc], mean difference = 19.8, 95% CI: −28.48–−16.45,p< 0.001 1.58 ± 1.18 [cc], mean difference=20.15, 95% CI: 5.96–15.97,p< 0.001). Mean pulmonary T2* values were lower in non-survivors in both lungs, the ipsilateral and contralateral lungs compared with the control group (81.83 ± 26.21 ms, mean difference = 31.13, 95% CI: −58.14–−10.32,p= 0.006; 81.05 ± 26.84 ms, mean difference = 31.91, 95% CI: −59.02–−10.82,p= 0.006; 82.62 ± 36.31 ms, mean difference = 30.34, 95% CI: −58.84–−8.25,p= 0.011) but no difference was observed between controls and CDH cases that survived.ConclusionsMean pulmonary T2* values were lower in CDH fetuses compared to controls and CDH cases who died compared to survivors. Mean pulmonary T2* values may have a prognostic function in CDH fetuses.ImpactThis study provides original motion-corrected assessment of the morphologic and functional properties of the ipsilateral and contralateral fetal lungs in the context of CDH.Mean pulmonary T2* values were lower in CDH fetuses compared to controls and in cases who died compared to survivors.Mean pulmonary T2* values may have a role in prognostication.Reduction in pulmonary T2* values in CDH fetuses suggests altered pulmonary development, contributing new insights into antenatal assessment.",s41390-025-04091-0,https://www.nature.com/articles/s41390-025-04091-0,Pediatric Research,2025-09-01,,incremental,2025-09-12T18:07:45,2025-09-12T18:07:45
147,Healthspan-lifespan gap differs in magnitude and disease contribution across world regions,"BackgroundLongevity gains have not been matched by equivalent advances in healthy longevity, giving rise to the healthspan-lifespan gap. This study maps, by world region, the healthspan-lifespan gap; identifies gap-associated demographic, economic, and health indicators; and deciphers disease burden patterns contributing to gap profiles.MethodsWorld Health Organization (WHO) Global Health Observatory, United Nations World Population Prospects and Global Health Expenditure Database were interrogated. The healthspan-lifespan gap was quantified from estimates of life expectancy and health-adjusted life expectancy. Regression analysis evaluated healthspan-lifespan gap correlates with a spatial error model used to adjust for confounders arising from geographic proximity. Dimensionality reduction by principal component analysis and clustering by machine learning discriminated disease burden patterns linked to healthspan-lifespan gap identity. Supervised machine learning enabled validation of disease burden pattern distinctness.ResultsCharted for six WHO-designated regions, comprising 183 member states, the healthspan-lifespan gap differs in size across regions. Life expectancy, gross domestic product, and noncommunicable disease burden most consistently correlate with the healthspan-lifespan gap. Unsupervised machine learning identifies three clusters delineating global morbidity patterns. Cluster-informed stratification discerns inter- and intra-regional gap heterogeneity. Africa, although exhibiting the narrowest healthspan-lifespan gap, is overrepresented in countries with larger than predicted healthspan-lifespan gaps and shows the greatest gap expansion and disease burden pattern restructuring. In contrast, Europe is overrepresented in countries with healthspan-lifespan gaps smaller than anticipated. Projections into 2100 forecast continuous widening of the healthspan-lifespan gap across regions.ConclusionsThe healthspan-lifespan gap is universal yet differs in magnitude and disease contribution among world regions. Gap identities imposed by distinct disease burden patterns caution against global generalization, necessitating region-informed solutions to maximize equitable healthy longevity.",s43856-025-01111-2,https://www.nature.com/articles/s43856-025-01111-2,Communications Medicine,2025-09-01,,incremental,2025-09-12T17:14:35,2025-09-12T17:14:35
146,Information-distilled physics informed deep learning for high order differential inverse problems with extreme discontinuities,"Standard physics informed deep learning and their enhanced variants encounter challenges in addressing inverse problems characterized by extreme discontinuities and high-order parameterized differential equations due to the use of globally smooth activation functions, especially when the unknown parameters exhibit spatially distributed characteristics. Phenomena such as discontinuous loads, boundary truncations, and abrupt changes in material properties introduce singularities in the derivatives, which in turn lead to ill-conditioned information in the gradient flow. To address these limitations, here we propose an information-distilled physics-informed deep-learning framework that combines reduced-order modeling, multi-level domain decomposition, and an ill-conditioning-suppression mechanism. The framework captures rapid variations in variables within highly localized regions induced by discontinuities. Through an information propagation mechanism and information distillation, the ill-conditioned information in the gradient flow of the system is suppressed. Even in scenarios where specific subnetworks fail, the framework preserves the accuracy of the majority of subnetworks.",s44172-025-00476-5,https://www.nature.com/articles/s44172-025-00476-5,Communications Engineering,2025-09-01,,incremental,2025-09-12T17:12:50,2025-09-12T17:12:50
141,China’s increasing flow of innovative assets into big pharma R&D pipelines,"Recent studies have highlighted increasing biomedical innovation originating from Asia—especially China—over the past decade1. Research and development (R&D) partnerships and licensing transactions often accelerate assets through the clinic by bringing complementary resources from smaller biotech companies and large pharmaceutical players. This article analyzes licensing deals and R&D partnership data over the 2020–2025 period for 11 big pharma companies—AbbVie, AstraZeneca, Bristol Myers Squibb (BMS), Eli Lilly, GSK, Johnson & Johnson (J&J), Merck, Novartis, Pfizer, Roche and Sanofi—to assess the emerging contribution of innovative assets from Asian biopharma to big pharma’s global R&D pipeline. The analysis could help gain insights into the portfolio and investment strategies of big pharma as they expand into the Chinese market.Go East“Go West, young man” was a famous piece of advice often attributed to Horace Greeley during the 1850s California gold rush. Lately, “Go East” is probably a more appropriate memo for pharma and biotech executives to venture into Asia’s vibrant biomedical ecosystems for licensing novel assets. Over the 2020−2025 period, the 11 big pharma companies included in this analysis have collectively committed >$150 billion for such deals, including >$17 billion in upfront and equity, to access innovative assets originating from Asia, primarily from China. Cumulatively these companies have sourced an estimated >50 innovative clinical/clinic-ready assets from Asia over this period—a vast majority of them from China—resulting in a median ~5.5% estimated share of their current clinical pipeline (versus a minimal contribution from Asia during the 2015−2020 period). GSK has the highest estimated share at ~10% of its pipeline comprising assets from Asia, followed by AstraZeneca and Merck at ~8.5%, while J&J, Pfizer and Roche have the lowest estimated shares at ~2−3%.Merck, AstraZeneca and BMS have been the most active dealmakers by dollar value, with Merck committing >$40 billion (including ~$6 billion in upfront and equity), AstraZeneca committing ~$25 billion (~$3 billion in upfront and equity) and BMS committing >$22 billion ($3 billion in upfront and equity) for Asian assets. In fact, one of the largest licensing transactions ever made by any big pharma was Merck’s deal with Daiichi Sankyo, Japan in 2023 for a portfolio of antibody−drug conjugates (ADCs), with an upfront of $4 billion and a total deal value of up to $22 billion.Eli Lilly, GSK and Novartis have also tapped into the broader Asian innovation ecosystem with significant transactions in Japan and South Korea, in addition to their Chinese partnerships. AbbVie, AstraZeneca, Eli Lilly, GSK and Novartis have made diversified bets across multiple therapy areas in cardiometabolic disease, central nervous system (CNS) disorders, immunology and oncology, while most other players are largely focused on oncology deals.China’s biotech licensing boomGlobal licensing deals and R&D partnerships had disclosed values of ~$170−180 billion per year over the 2020−2025 period. While the overall annual deals value during this period was largely flat, a notable aspect was that the value of licensing deals for assets originating from China increased >10 times (Fig. 1), from ~$5 billion in 2020 (~3% of global value) to >$50 billion in 2024 (~30% of global value), highlighting the increasing innovation from China. Furthermore, China accounts for roughly a third of global clinical assets, on a par with the United States and significantly ahead of Europe1.Fig. 1 | Chinese licensing deals 2020–2025.Chinese biopharma assets account for a growing share of licensing deals. Data for 2025 have been extrapolated to a full year using Q1 and Q2 2025 data. Source: Evaluate 2025,Nat. Biotechnol. 43, 1028–1034 (2025).The 11 big pharma companies included in this study collectively committed ~$100 billion for Chinese deals during 2020−2025 (Fig. 2), including ~$11 billion in upfront and equity, accounting for ~65% of their overall Asia commitments. BMS, AstraZeneca, Merck and Novartis have been the most active dealmakers in China by dollar value during this period, with BMS, AstraZeneca and Merck each committing ~$19 billion in total deal value and ~$2 billion in upfronts, while Novartis has committed ~$12 billion in total value and ~$1.5 billion in upfronts. These investments are targeted at building their next-generation oncology (ADCs, programmed cell death 1 ligand 1 [PD-(L1)1] × vascular endothelial growth factor [VEGF] and T-cell engagers), cardiometabolic disease/obesity (including glucagon-like peptide 1 [GLP-1] proteins) and cell therapy (chimeric antigen receptor T cell [CAR-T]) pipelines.With respect to therapy area/modalities, the cohort in this analysis has collectively committed ~$27 billion for ADCs (including ~$2 billion in upfront and equity), >$20 billion for PD-(L)1×VEGF (>$3 billion in upfronts) and ~$4 billion for T-cell engagers (~$1 billion in upfronts) for the oncology therapy area; ~$15 billion for the cardiometabolic area (including GLP-1 proteins); and ~$8 billion for immunology (small molecule and antibody) assets from China.Additionally, AstraZeneca, Eli Lilly and Sanofi have made significant bets on artificial intelligence (AI)-driven drug discovery partnerships in China. An area where Chinese biopharma continues to lag, however, is CNS disorders: there have been no significant transactions in this therapeutic area by the big pharma cohort discussed here. By contrast, Japan and South Korea biopharma have had several significant deals with big pharma in this space.Fig. 2 | Selected deals between big pharma and Chinese biopharma between January 2020 and 15 June 2025.Only deals with >$200 million disclosed values are included. Some have not disclosed all financials, such as the Johnson and Johnson (J&J)–Cellular Biomedicine Group (CBMG) deal which disclosed only the upfronts. The ‘Others’ modality includes oncology, small-molecule, respiratory-asset and artificial intelligence (AI) drug discovery transactions. ADC, antibody–drug conjugate; CAR-T, chimeric antigen receptor T cell; PD-(L1)1, programmed cell death 1 ligand 1; VEGF, vascular endothelial growth factor.Big pharma strategic considerationsThe recent wave of innovative assets from China, and the increasing interest from big pharma, are a maturation of the focused biomedical investments, therapy area capabilities and technology platforms that China has built over the past decade2,3,4.Many assets have also become more readily available for licensing in China as their development has been facilitated through the introduction of some regulatory policies. The 2015 ‘Opinions on the Reform of Review and Approval Process for Drugs and Medical Devices’ guidance was put into place, followed by the 2020 revision of the ‘Provisions for Drug Registration’ which included several accelerated drug marketing registration procedures (ADMRPs), designed to accelerate time-to-market for many drugs5.A key strategic consideration for big pharma is the large substrate of clinical stage ‘leapfrog’ opportunities available in China, and broadly across Asia, for newer modalities. A good case study is the ADCs space. Once Pfizer acquired Seagen and AbbVie acquired ImmunoGen—two leading ADC players in the West—peer pharma companies such as AstraZeneca, BMS, GSK and Merck (all of which likely competed in bids for Seagen and ImmunoGen) pivoted to Asia for accessing clinical-stage ADCs. A similar strategy is likely unfolding for the cell-therapy/CAR-T space (AstraZeneca−Gracell and Novartis−Legend Biotech) and GLP-1 proteins (AstraZeneca−Eccogene).",d43747-025-00065-7,https://www.nature.com/articles/d43747-025-00065-7,Biopharma Dealmakers,2025-09-01,,incremental,2025-09-12T16:59:33,2025-09-12T16:59:33
140,Delivering on RNA therapeutic deals,"Drugmakers can now call on a host of RNA therapeutic modalities, but small-interfering RNA (siRNA) and antisense oligonucleotide (ASO) drugs still garner the highest upfront payments. Oligo therapies claimed nine of the top 10 grossing transactions in the last year (12 months from the third fiscal quarter (Q3) of 2024 through Q2 2025). And 2025 has been notable in marking the first acquisition of a clinical-stage ASO program targeting a microRNA (miRNA) by a multinational pharmaceutical company. Licensing of RNA-editing technology also came to the fore, with five deals and a median value of $1.3 billion. But perhaps the most compelling trend in the dealmaking landscape has been an uptick in transactions around companies offering solutions for RNA drug delivery and manufacturing. Clearly, RNA-targeted drugs are a fast-evolving space. As Myles Minter, a senior biotechnology healthcare analyst at William Blair, put it: “For the past couple of years, we’ve been witnessing a true renaissance in RNA-targeted therapeutics.” And a premium is currently being placed on companies that can deliver RNA drugs to tissues other than the liver. The race is on to see which will deliver.Notable mergersAcross biotech, 2025 got off to a flying start with flagship multibillion-dollar mergers such as Johnson & Johnson’s acquisition of Intra-Cellular Therapies and Novartis’ takeover of Anthos Therapeutics. While that initial flow of banner deals has now slowed, plenty of smaller buyouts have still been taking place, with cash-rich buyers looking to snap up cash-strapped biotechs at low valuations. In the RNA space, merger activity was less intense, but several deals caught the eye.In April 2025, Switzerland-based Novartis acquired Regulus Therapeutics, a San Diego-based biopharma, for $800 million upfront, 18 years after it was founded by Alnylam Pharmaceuticals and Ionis Pharmaceuticals. A month earlier, Regulus had announced the successful completion of a phase 1b multiple-ascending-dose trial for farabursen, an ASO targeting miRNA-17 (miR-17) in autosomal dominant polycystic kidney disease. Considering the checkered clinical history of miRNA-targeted therapies, Regulus’ phase 1b trial data showed promising clinical efficacy and safety, including positive results on the mechanistic biomarkers urinary polycystin 1 (PC1) and PC2. This transaction represents the first acquisition of a clinical-stage miRNA program by big pharma. According to investor and entrepreneur John Maraganore, who co-founded Regulus as CEO of Alnylam together with Stan Crooke, executive chairman, founder and CEO of Ionis, “Amazing. This is a validation of the miRNA space; there’s definitely more to come.”In June 2025, BioNTech made an even bigger splash, acquiring CureVac in an all-stock deal worth about $5.46 per share, valuing the RNA vaccine maker at ~$1.25 billion. The deal represents a marriage of two European pioneers in miRNA vaccines. BioNTech has already been blazing a trail with autogene cevumeran, its personalized mRNA oncology vaccine for pancreatic cancer; the acquisition of CureVac broadens its oncology offering. Last year, CureVac sold rights to its mRNA-based preventative vaccines for COVID-19 and influenza to GSK for $432 million, ostensibly so that it could focus on its lead multiepitope mRNA vaccine in phase 1 for resected glioblastoma. BioNTech cited oncology programs as impetus for the deal, but analysts also pointed out that the merger neatly resolved BioNTech’s patent litigation with CureVac, avoiding a payout of potential royalties on ~$32 billion sales of its COVID-19 vaccine Comirnaty. Another important facet of the CureVac trade sale is access to CureVac’s RNA-manufacturing capacity in Tübingen, Germany.RNA manufacturing to the foreThis dovetailed with several other big acquisitions in the RNA space focused on manufacturing. In June 2024, GSK acquired Elsie Biotechnologies for up to $50 million to access its oligonucleotide-synthesis technologies. Three months later, Agilent Technologies completed the acquisition of Biovectra for $925 million in a move to expand Agilent’s contract development and manufacturing capabilities for oligos and guide-RNAs.Elsewhere, Maravai LifeSciences undertook two mergers to bolster the presence of its subsidiary TriLink BioTechnologies in commercial RNA manufacturing. In January 2025, it acquired certain assets and intellectual property (IP) from Molecular Assemblies; this followed a November 2024 buyout of AI-enabled mRNA design and manufacture specialist Officinae Bio. These takeovers are part of a trend in which developers are seeking solutions to several RNA-manufacturing challenges—including mRNA purification, lipid-nanoparticle (LNP)-formulation stability, and the need to replace hazardous organic solvents—that stand in the way of widespread adoption of mRNA drugs.“We shouldn’t be surprised,” said Minter. “As RNA-targeted drug sponsors are moving from rare diseases to much more prevalent ones, you can see that the pure quantities of oligos required from the supply chain will be completely different.” He contrasted Ionis’ Spinraza (nusinersen), which has a market of ~3,000 patients, with Alnylam’s Leqvio (inclisiran), which in the secondary prevention market in cardiovascular disease aims for 15 million. Getting to that scale will require manufacturing muscle and innovation. Maraganore agreed: “Ton-scale manufacturing is going to really tax existing capabilities, so there’s a lot of interest in new technologies for scaling siRNA production including things like enzymatic ligation of blockmers [short single-stranded oligonucleotides used to bridge RNA synthesis].”ASO and siRNA premiumsAlthough there were just nine mergers involving RNA-based products over the past year, >60 licensing deals centered around RNA therapeutic assets or technology. J.P. Morgan reported that the first fiscal quarter (Q1) of 2025 saw “higher upfront payments for licensing transactions as pharmas searched for less-risky deals to fill pipelines, with the appetite highest for […] assets and platforms in the later stages of clinical development”.Nowhere has this been clearer than for ASO and siRNA oligos (Table 1). “There is very strong enthusiasm for siRNAs and ASOs right now,” said Maraganore. “These categories continue to be of great interest to pharma and larger biotech companies.” The ASO flagship Ionis Pharmaceuticals has continued to out-license parts of its pipeline: last November, Otsuka Pharmaceuticals paid $10 million upfront for worldwide rights to ulefnersen, currently in phase 3 for the RNA-binding protein fused in sarcoma (FUS) in amyotrophic lateral sclerosis (ALS); in December, Theratechnologies paid $10 million upfront for Canadian marketing rights for Tryngolza (olezarsen), currently in phase 3 trials against familial chylomicronemia syndrome/severe hypertriglyceridemia and for donidalorsen in phase 3 trials for hereditary angioedema; and Ono Pharmaceuticals paid $280 million for worldwide rights to develop sapablursen in phase 2 trials for polycythemia vera. Two other deals were notable: Biogen’s February deal for Stoke Therapeutics’ zorevunersen, an ASO that targets a poison exon in the sodium voltage-gated channel alpha subunit 1 (SCN1A) for treating Dravet syndrome, with $165 million upfront and $385 million in milestones and royalties; and Lilly’s $13 million license from Creyon Bio for access to the startup’s machine-learning models for ASO design. Other ASO companies making deals without disclosing terms include CAMP4 Therapeutics with Biomarin, and Oak Hill Bio with Roche.In the siRNA space, Alnylam continues to defer from licensing, but Arrowhead Pharmaceuticals sealed a $825 million blockbuster deal in November 2024 with Sarepta Therapeutics for several musculoskeletal siRNA programs (Table 1). That deal apart, the lion’s share of licensing involved smaller companies like Sirnaomics, ADARx Pharmaceuticals, OliX Pharmaceuticals, Synerk, and City Therapeutics.Similar to the larger biopharma space, it is also clear that Chinese oligo developers are getting in on the act. In June 2024, Starna Therapeutics signed a research partnership with RecoRNA Biotechnology to discover and develop therapies using Starna’s LNP platform and RecoRNA’s RNA-editing platform for lung diseases. In January 2024, Argo Biopharmaceutical, whose co-founder and CSO Patrick Shao is a former director of medicinal chemistry at Arrowhead, licensed a phase 1 siRNA asset against an undisclosed cardiovascular target and two additional siRNA programs for cardiovascular disease to Novartis for $185 upfront and a total value that could reach $4.2 billion (Table 1). And in May 2025, for a $95 million upfront, Sirius Therapeutics granted CRISPR Therapeutics exclusive rights to co-develop SRSD-107, a long-acting coagulant factor XI siRNA for thromboembolic disorders, with an option for two more siRNA targets (Table 1).Table 1 | RNA therapeutic deals ranked by value of upfront paymentDateOut-licensor/sellerIn-licensee/buyerUpfront payment ($ million)Therapeutic modalityFocus26 November 2024Arrowhead PharmaceuticalsSarepta Therapeutics825siRNAPhase 1/2 programs for facioscapulohumeral muscular dystrophy 1, myotonic dystrophy, idiopathic pulmonary fibrosis, and spinocerebellar ataxia plus three preclinical programs14 May 2025ADARx PharmaceuticalsAbbVie335siRNAsiRNAs against undisclosed CNS, immunology and oncology targets11 March 2025Ionis PharmaceuticalsOno Pharmaceuticals280ASOWorldwide rights to develop sapablursen, which is in phase 2 trials for polycythemia vera7 January 2024Argo Bio-pharmaceuticalNovartis185siRNAsiRNA against an undisclosed target, with two additional programs for cardiovascular disease18 February 2025Stoke TherapeuticsBiogen165ASOEx-American rights to develop zorevunersen for Dravet syndrome19 May 2025Sirius TherapeuticsCRISPR Therapeutics95siRNAEx-China rights to SRSD-107, a long-acting siRNA against coagulation factor XI for thromboembolic disorders6 April 2025ABL BioGSK49.64siRNA/ASOExclusive worldwide rights to blood–brain barrier shuttle targeting IGF1R27 May 2025City TherapeuticsBiogen46siRNACITY siRNAs against undisclosed CNS targets3 June 2024QurAlisEli Lilly45ASOWorldwide rights to QRL-204, a splice-switching ASO restoring UNC13A in ALS, frontotemporal disorder, and other CNS diseases18 June 2024Ascidian TherapeuticsRoche42RNA editingWorldwide target-specific rights to develop an RNA trans-splicing exon editing platform for undisclosed CNS indicationsALS, amyotrophic lateral sclerosis; ASO, antisense oligonucleotide; CITY, mRNA cleavage-inducing tiny; CNS, central nervous system; IGF1R, insulin-like growth factor 1 receptor; siRNA, small-interfering RNA; UNC13A, protein unc-13 homolog A.New chemistries and formatsIn the oligo space, several deals focused on new chemistries/modes of action. In October 2024, Maraganore co-founded City Therapeutics, which is developing mRNA cleavage-inducing tiny (CITY) siRNAs. In January 2025, City formed a research and development (R&D) partnership with Bausch + Lomb worth up to $485 million for targets in the eye. And in May 2025, it granted Biogen exclusive worldwide rights to develop oligos against central nervous system (CNS) diseases for $46 million upfront, with City eligible for up to $1 billion in milestones, plus tiered royalties (Table 1).For ASO oligos, Lilly struck a deal last September with HAYA Therapeutics, paying up to $1 billion in milestones and royalties for access to the startup’s 15-mer gapmer locked-nucleic acid ASOs targeting long noncoding RNAs for obesity and related metabolic conditions. In January 2025, Sanofi paid $27.5 million in upfront fees, with eligibility for >$400 million in milestones and tiered royalties, to access Alloy Therapeutics novel oligo formats based on Sudhir Agarwal’s 5ʹ-5ʹ linked cyclic splitmer ASO technology. The cyclic oligos show greater specificity and potency than gapmers, potentially opening up broader therapeutic windows.With Wave Therapeutics and Korro Bio dosing their first alpha-1 antitrypsin (AAT) deficiency patients, excitement has also been building around RNA editors. Last September, Korro granted Novo Nordisk exclusive rights to develop two double-stranded RNA-specific adenosine deaminase (ADAR) therapies for cardiometabolic disease, with the startup receiving up to $530 million. And two deals were clinched for RNA trans-splicing platforms: in June 2024, Ascidian Therapeutics received $42 million upfront and up to $1.8 billion in milestones and royalties from Roche to develop RNA exon-editing therapies for CNS indications (Table 1); and in May 2025, Rznomics signed an up to $1.3 billion research partnership with Lilly to co-develop RNA-editing therapies using the startup’s ribozyme platform for hearing loss.",d43747-025-00060-y,https://www.nature.com/articles/d43747-025-00060-y,Biopharma Dealmakers,2025-09-01,,incremental,2025-09-12T16:59:33,2025-09-12T16:59:33
117,Brain–computer interface control with artificial intelligence copilots,"Motor brain–computer interfaces (BCIs) decode neural signals to help people with paralysis move and communicate. Even with important advances in the past two decades, BCIs face a key obstacle to clinical viability: BCI performance should strongly outweigh costs and risks. To significantly increase the BCI performance, we use shared autonomy, where artificial intelligence (AI) copilots collaborate with BCI users to achieve task goals. We demonstrate this AI-BCI in a non-invasive BCI system decoding electroencephalography signals. We first contribute a hybrid adaptive decoding approach using a convolutional neural network and ReFIT-like Kalman filter, enabling healthy users and a participant with paralysis to control computer cursors and robotic arms via decoded electroencephalography signals. We then design two AI copilots to aid BCI users in a cursor control task and a robotic arm pick-and-place task. We demonstrate AI-BCIs that enable a participant with paralysis to achieve 3.9-times-higher performance in target hit rate during cursor control and control a robotic arm to sequentially move random blocks to random locations, a task they could not do without an AI copilot. As AI copilots improve, BCIs designed with shared autonomy may achieve higher performance.",s42256-025-01090-y,https://www.nature.com/articles/s42256-025-01090-y,Nature Machine Intelligence,2025-09-01,,incremental,2025-09-12T16:47:07,2025-09-12T16:47:07
